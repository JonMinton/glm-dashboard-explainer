<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Understanding GLMs - An Interactive Guide – claude-concept-chat</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Understanding GLMs - An Interactive Guide</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../pages/index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-guided-tour" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Guided Tour</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-guided-tour">    
        <li>
    <a class="dropdown-item" href="../pages/index.html" rel="" target="">
 <span class="dropdown-text">1. Choose a Scenario</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../pages/data.qmd" rel="" target="">
 <span class="dropdown-text">2. Explore Your Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../pages/model.qmd" rel="" target="">
 <span class="dropdown-text">3. Build Your Model</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../pages/transform.qmd" rel="" target="">
 <span class="dropdown-text">4. Transform Predictors</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../pages/fit.qmd" rel="" target="">
 <span class="dropdown-text">5. Fit the Model</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-advanced" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Advanced</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-advanced">    
        <li>
    <a class="dropdown-item" href="../pages/advanced/loss-functions.qmd" rel="" target="">
 <span class="dropdown-text">Comparing Loss Functions</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/JonMinton/glm-dashboard-explainer" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Understanding GLMs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pages/model-builder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Build Your Model</span></a>
  </div>
</li>
        <li class="sidebar-item">
 <span class="menu-text">pages/transform.qmd</span>
  </li>
        <li class="sidebar-item">
 <span class="menu-text">pages/fit.qmd</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Advanced</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
 <span class="menu-text">pages/advanced/loss-functions.qmd</span>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><div class="quarto-title-block"><div class="quarto-title-tools-only"><h1></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>



<p>Let’s develop a storyboard or interactive tool description for demonstrating how generalised linear models work. What are your initial ideas? We’ll ‘riff’ on this19 NovI’m thinking about what makes GLMs click for people, and I reckon the key insight is seeing how the link function transforms the linear predictor into the response scale. Most people grasp linear regression intuitively, but GLMs add this extra layer of abstraction that can feel opaque. Here are a few directions we could explore: 1. The “fitting room” concept Show how different distributions are like different clothing that data needs to wear. You’ve got count data trying to squeeze into a normal distribution (doesn’t fit!), then we try Poisson (perfect fit). The link function is the transformation that makes the linear model’s predictions compatible with each distribution’s constraints. 2. Interactive link function explorer A tool where you manipulate a linear predictor (drag sliders for coefficients), and watch in real-time how different link functions (logit, log, identity, probit) transform that straight line into curves on the response scale. Split view: left side shows the linear predictor space, right side shows the transformed predictions with actual data points overlaid. 3. The “constraint satisfaction” narrative Frame it as: “We want to do linear regression, BUT our response variable breaks the rules (negative counts? probabilities outside 0-1?). How do we make predictions that respect the constraints whilst keeping our beloved linear model?” Show the link function as the clever compromise. 4. Residual patterns detective Start with someone fitting regular linear regression to inappropriate data (binomial, count, gamma). Show the diagnostic plots looking terrible. Then progressively introduce: “What if we transform the response? What if we change the error distribution? What if we do both systematically?” Build up to the GLM framework as the principled solution. Which of these resonates? Or have they sparked a different direction entirely?Let’s think how we might develop an interactive page for explaining how GLMs work.&nbsp;Think of three core components:1) Response Transformers: g(.). These transform the response as you suggest. 2) Noisemakers: f(.). These allow stochasticity to be represented. 3) Predictor transformers: h(.). These transform part of the predictor matrix X so as to make it closer to normally distributed.Could you imagine how an interactive tool could be developed which shows how different types of data can be represented using these three types of component?19 NovThis is a brilliant decomposition! You’re essentially separating the systematic component (predictors), the random component (error distribution), and the link between them. Let me sketch out how an interactive tool could work: Core Interface Structure Three-panel layout: Panel 1: Data Generator (left side)</p>
<p>User selects a “data scenario” from dropdown or cards:</p>
<p>“Hospital readmissions” (binomial) “Insurance claims count” (Poisson/negative binomial) “Time to equipment failure” (gamma/exponential) “Air quality measurements” (Gaussian)</p>
<p>Underlying truth: you generate data where X → η (linear predictor) → μ (mean) → Y (response)</p>
<p>Panel 2: Component Workshop (centre, the meat of it) Three interactive sections stacked vertically:</p>
<p>Predictor Transformers h(X)</p>
<p>Toggles/dropdowns for each predictor: [Raw | Log | Square root | Polynomial | Spline] Live scatter plots showing marginal distributions before/after transformation Maybe a normality test statistic updating in real-time Visual: overlaid density curves showing “how normal is this now?”</p>
<p>Response Transformers g(μ)</p>
<p>Dropdown: [Identity | Log | Logit | Probit | Inverse] Visual representation: show the function curve itself Key insight display: “This maps (-∞, ∞) to [a, b]” with the actual bounds shown</p>
<p>Noisemakers f(Y|μ)</p>
<p>Distribution family selector: [Gaussian | Poisson | Binomial | Gamma | Neg. Binomial] Interactive parameters (where relevant): dispersion, trials for binomial, etc. Visual: show probability mass/density function updating as μ changes Maybe animate: “If μ = 5, here’s what Y values look like…”</p>
<p>Panel 3: Diagnostic Dashboard (right side) Real-time fitting and diagnostics:</p>
<p>Deviance residuals vs fitted Q-Q plot Residuals vs linear predictor A “badness of fit” meter (simplified deviance or AIC) Coefficient estimates with SEs</p>
<p>The Interactive Flow Mode 1: Guided Discovery</p>
<p>Present data, deliberately fit wrong model (normal identity link to count data) Diagnostics look terrible—patterns everywhere Prompt user: “The problem is [X]. Try changing [component Y]” When they fix it, diagnostics improve dramatically Positive reinforcement: “Notice how the residual pattern disappeared!”</p>
<p>Mode 2: Sandbox Exploration</p>
<p>Load any dataset or simulation User experiments freely with all three components Tool shows “conventional choice” badge when they select the standard GLM for that data type But allows weird combinations: “Poisson with identity link—see what happens!”</p>
<p>Key Interactive Features Linked brushing:</p>
<p>Hover over a data point → see it highlighted across all panels See its contribution to deviance, its residual, where it falls in the predictor space</p>
<p>Animation of the data generation process:</p>
<p>Step through: X → h(X) → β’h(X) → g⁻¹(β’h(X)) = μ → f(Y|μ) → observed Y Show the transformation at each stage with actual numbers for selected observations</p>
<p>“What if?” sliders:</p>
<p>Change β coefficients and watch predictions update Change dispersion parameter and see variance in f(.) widen/narrow Watch how changing h(.) affects the linearity assumption</p>
<p>Comparison mode:</p>
<p>Split screen: fit two different models side-by-side Direct visual comparison of residual plots and fit statistics</p>
<p>Technical Implementation Thoughts React components structure:</p>
<p><datascenario> - handles data generation and state <transformerpanel> - the three transformer controls</transformerpanel></datascenario></p>
<p><predictortransformer> <linkfunction> <errordistribution></errordistribution></linkfunction></predictortransformer></p>
<p><diagnosticsdashboard> - recharts visualisations <modelfitter> - probably calls a WebAssembly-compiled GLM fitter or servers-side R API</modelfitter></diagnosticsdashboard></p>
<p>For actual GLM fitting: You could either:</p>
<p>Call a lightweight JavaScript GLM library (glmnet.js if it exists, or roll your own for simple cases) Use WebAssembly to compile R’s glm() function Server-side: hit an R/Python API endpoint (Plumber or FastAPI)</p>
<p>Given your R preference, option 3 might be cleanest for prototyping: React frontend, Plumber backend doing the heavy lifting. Educational Scaffolding Progressive disclosure:</p>
<p>Beginner mode: only show appropriate transformers for each data type Intermediate: show all options but flag inappropriate ones Advanced: complete freedom + show the maths</p>
<p>Conceptual annotations:</p>
<p>When user selects logit link: “This is for proportions/probabilities. It maps the linear predictor (any real number) to (0,1)” When residual patterns appear: “See this funnel shape? That’s heteroskedasticity—variance isn’t constant”</p>
<p>Does this capture what you’re imagining? The key question is whether we want this to be purely demonstrative, or also actually functional for real data analysis?Let’s zoom in on the ‘what if’ slider part for now. A key thing I want to demonstrate is that maximum likelihood is one of many theoretically possible loss functions, though one which can be strongly demonstrated from first principles. It would be good to have options to manually toggle beta and alpha (noisemaker) parameters, but also to select different algorithms and loss functions to do this too. How might that work?19 NovAh, this is excellent! You want to expose the optimisation landscape itself and show that MLE is a choice, albeit a principled one. Let me think through how this could work: Control Panel Structure Manual Controls Section:</p>
<p>Sliders for each β coefficient (β₀, β₁, β₂…) Slider(s) for dispersion/scale parameters (φ for quasi-likelihood, overdispersion for NB, etc.) Real-time updates: as you drag, watch predictions and loss function value change</p>
<p>Optimisation Section: Two dropdown menus side-by-side: 1. Loss Function Selector:</p>
<p>Maximum Likelihood (deviance) Least Squares (MSE on response scale) Least Squares on transformed scale (MSE on g(μ) scale) Least Absolute Deviation (L1 loss) Huber loss (robust) Custom: user enters their own function?</p>
<ol start="2" type="1">
<li>Algorithm Selector:</li>
</ol>
<p>Iteratively Reweighted Least Squares (IRLS) [the standard] Newton-Raphson Gradient Descent Nelder-Mead (derivative-free) Coordinate Descent Manual (slider control only)</p>
<p>Then an “Optimise” button that runs the selected algorithm with the selected loss. Visual Feedback Components 1. Loss Surface Visualisation This is crucial for intuition. For 2 parameters (say β₀ and β₁):</p>
<p>Contour plot of the loss function in (β₀, β₁) space Current parameter values shown as a point As algorithm runs, show the trajectory of the optimisation path Different algorithms trace different paths to the minimum</p>
<p>For &gt;2 parameters, could show:</p>
<p>2D slices through the loss surface (fix all but two parameters) Or parallel coordinates plot showing parameter evolution over iterations</p>
<ol start="2" type="1">
<li>Loss Function Value Tracker</li>
</ol>
<p>Real-time numeric display: “Current loss: 234.56” Line plot showing loss decreasing over iterations when algorithm runs Compare multiple algorithms: overlaid traces showing convergence speed</p>
<ol start="3" type="1">
<li>Algorithm Diagnostics Panel When an algorithm is running/has run:</li>
</ol>
<p>Iteration count Convergence status (gradient norm, relative change in loss) For IRLS specifically: show the working weights evolving Step size (for gradient descent variants)</p>
<ol start="4" type="1">
<li>Split View: Predictions Panel</li>
</ol>
<p>Top: fitted values overlaid on data Bottom: residuals Updates in real-time as β changes (manual or algorithmic)</p>
<p>The Interactive Workflow Workflow 1: Manual Exploration</p>
<p>User loads data (say, Poisson count data) Sets algorithm to “Manual” Moves β sliders around Watches:</p>
<p>Loss function value change Their position move on the contour plot Fitted line move on the data plot Residual patterns shift</p>
<p>Tries to minimise loss themselves (gamification!) Then clicks “Optimise with IRLS” to see the algorithm find it instantly</p>
<p>Workflow 2: Loss Function Comparison</p>
<p>Fit Poisson data with Maximum Likelihood → get β̂_ML Switch loss to “Least Squares” → optimise again → get β̂_LS Display both sets of coefficients side-by-side Show both fitted lines on the same plot Key insight: “See how LS gives more weight to outliers?”</p>
<p>Workflow 3: Algorithm Racing Split the contour plot into 3-4 panels, each running a different algorithm simultaneously from the same starting point:</p>
<p>IRLS (top-left) Gradient Descent (top-right) Newton-Raphson (bottom-left) Nelder-Mead (bottom-right)</p>
<p>Animate them converging at different speeds, different paths. Some might overshoot, some take more iterations. Deep Dive: The Loss Function Maths Display When user hovers over or selects a loss function, show a formula panel: For Maximum Likelihood (Poisson): L(β) = Σᵢ [yᵢ log(μᵢ) - μᵢ - log(yᵢ!)] where μᵢ = exp(Xᵢβ)</p>
<p>Deviance: D = 2Σᵢ [yᵢ log(yᵢ/μᵢ) - (yᵢ - μᵢ)] For Least Squares: L(β) = Σᵢ (yᵢ - μᵢ)² For Least Squares (link scale): L(β) = Σᵢ (g(yᵢ) - ηᵢ)² where ηᵢ = Xᵢβ Accompanying text: “MLE comes from assuming data are i.i.d. draws from f(y|μ). It’s not just convenient—it’s what probability theory tells us to maximise.” Demonstrating Why MLE is Special Interactive Demonstration:</p>
<p>Efficiency comparison:</p>
<p>Generate data from known β Fit with MLE vs LS repeatedly (bootstrap/simulation) Show sampling distributions of β̂: MLE should have tighter distribution Display: “MLE is asymptotically efficient—smallest variance among consistent estimators”</p>
<p>Consistency under misspecification:</p>
<p>Generate overdispersed Poisson (negative binomial really) Fit with Poisson MLE Show: β̂ still consistent! (SE wrong, but estimates okay) Fit with LS: β̂ might be biased</p>
<p>The deviance connection:</p>
<p>Show that MLE naturally gives you deviance Deviance → likelihood ratio tests → nested model comparisons Other loss functions don’t give you this inferential framework Visual: tree of nested models with deviance differences</p>
<p>Technical Implementation Details Loss function calculation (in R backend or JS): javascriptconst lossFunctions = { mle_poisson: (y, mu) =&gt; -sum(y.map((yi, i) =&gt; yi * Math.log(mu[i]) - mu[i])),</p>
<p>least_squares: (y, mu) =&gt; sum(y.map((yi, i) =&gt; Math.pow(yi - mu[i], 2))),</p>
<p>least_squares_link: (y, eta, linkFn) =&gt; sum(y.map((yi, i) =&gt; Math.pow(linkFn(yi) - eta[i], 2))),</p>
<p>// etc. } Optimisation algorithms: For IRLS, you’d need the working weights and adjusted dependent variable. This probably wants to live in R: r# Plumber API endpoint #* <span class="citation" data-cites="post">@post</span> /optimise function(X, y, family, link, loss_fn, algorithm) { if (loss_fn == “mle” &amp;&amp; algorithm == “irls”) { fit &lt;- glm(y ~ X - 1, family = family) return(list( coefficients = coef(fit), iterations = fit<span class="math inline">\(iter,  converged = fit\)</span>converged, trajectory = fit$trace # if we store it )) } # … other combinations } For the contour plot:</p>
<p>Pre-compute loss on a grid of (β₀, β₁) values Use Plotly or D3 for interactive contours Overlay the optimisation path as a line with markers at each iteration</p>
<p>Pedagogical Sequencing Level 1: Discovery</p>
<p>Hide the maths initially Just show: “Different ways to measure fit” Let them see that different loss functions → different β̂</p>
<p>Level 2: Understanding</p>
<p>Reveal the formulas Show the connection: MLE ↔︎ assumed distribution Demonstrate efficiency via simulation</p>
<p>Level 3: Advanced</p>
<p>Show score functions (gradient of log-likelihood) Fisher information Why IRLS works: connection to Newton-Raphson with expected rather than observed Hessian</p>
<p>Does this align with your vision? The key tension I see is between pedagogical clarity (keep it simple) and completeness (show all the options). Perhaps we need user-selectable “modes”: Basic, Intermediate, Advanced?To avoid information overload let’s think how we can guide the user one step at a time, through having one page at a time, which cannot be skipped unless interacted with. To start with the first page could just be a list of scenarios, describing types of problem that can be addressed with statistical modelling. The second page would then allow the user to see the data associated with the scenario. The third page would introduce different types of GLM, the kinds of problems they are used for, and as advanced material their likelihood function. The page after that would then describe some predictor transformers. The page after that would then be when the user starts fitting the data to the model.19 NovExcellent! A linear, guided tour structure prevents cognitive overload and builds understanding progressively. Let me sketch out this page-by-page journey:</p>
<p>Page 1: Scenario Selection Title: “What are you trying to understand?” A card-based interface with 5-6 scenarios: Card layout (each shows an icon, title, one-sentence description):</p>
<p>Hospital Readmissions “Will patients return within 30 days? Binary outcomes from medical records.” Insurance Claims Volume “How many claims will we receive? Count data with no upper limit.” Species Abundance “Counting organisms at different sites. Ecology data with excess zeros.” Equipment Lifespan “When will machines fail? Positive continuous data, right-skewed.” Crop Yields “Tonnes per hectare under different treatments. Continuous with constant variance.” Market Survey Response “How satisfied are customers? Ordinal categories from 1-5.”</p>
<p>Interaction: User clicks one card. It expands slightly, others fade. A “Continue” button appears. Purpose: Prime them to think about data types and question types before seeing any maths.</p>
<p>Page 2: Explore Your Data Title: “Hospital Readmissions: What does the data look like?” Main visual: Large scatter plot or strip plot showing the data</p>
<p>X-axis: a key predictor (e.g., “Length of initial stay (days)”) Y-axis: binary outcome (0 = no readmission, 1 = readmission) Points jittered vertically for visibility Maybe add a smoother/loess curve overlaid</p>
<p>Side panel: Data summary statistics</p>
<p>N observations Proportion of 1s vs 0s Range of predictor A few example rows shown in a mini table</p>
<p>Interactive elements:</p>
<p>Dropdown to switch which predictor is shown (if multivariate) Toggle: “Show raw data” vs “Show proportion in bins” (bin the x-axis, show success rate per bin)</p>
<p>Key text callout: “Notice: The outcome is binary (0 or 1), but when we group patients by similar characteristics, the readmission rate varies between 0% and 100%. We need a model that respects these boundaries.” Bottom of page: “Continue” button (always visible once they’ve interacted with the chart) Purpose: Let them see the problem before solving it. Build intuition about what the model needs to capture.</p>
<p>Page 3: Choosing Your Model Family Title: “Different data, different models” Main content: A matrix/table layout Data TypeExampleGLM FamilyWhy this worksBinary (0/1)Readmission?Binomial (Logistic)Maps probabilities to whole real lineCountsNumber of claimsPoissonNon-negative integers onlyCounts (overdispersed)Species with many zerosNegative BinomialAllows more variance than PoissonPositive continuousTime to failureGammaPositive values, right-skewedContinuousCrop yieldGaussianSymmetric, unbounded Your scenario is highlighted (e.g., the Binomial row glows/is emphasised) Interactive element:</p>
<p>Click on each row to expand it Expansion shows:</p>
<p>A small plot of the probability/density function shape The link function (name only at this stage): “logit”, “log”, “identity” One-sentence: “Use this when…”</p>
<p>“Show me the maths” toggle (collapsed by default): When expanded, shows for the highlighted row: For Binomial/Logistic: Pr(Y = 1 | X) = π π = g⁻¹(Xβ), where g(π) = log(π/(1-π)) [logit link]</p>
<p>Likelihood: L(β) = ∏ᵢ πᵢʸⁱ(1-πᵢ)⁽¹⁻ʸⁱ⁾ Log-likelihood: ℓ(β) = Σᵢ [yᵢ log(πᵢ) + (1-yᵢ) log(1-πᵢ)] Key pedagogical text: “The GLM family determines two things: (1) what values Y can take, and (2) how the variance relates to the mean. Maximum likelihood uses this information to find the best-fitting β.” Bottom: “Continue with Binomial GLM” button Purpose: Connect data type → model family. Plant the seed that likelihood depends on distributional assumptions.</p>
<p>Page 4: Preparing Your Predictors Title: “Should we transform the predictors?” Context reminder (small banner at top): “You’re modelling hospital readmissions (binary) using length of stay as a predictor.” Main visual: Split panel Left panel: Current predictor</p>
<p>Histogram of X (length of stay) Summary stats: mean, SD, range Shape description: “Right-skewed, most stays are short, a few very long”</p>
<p>Right panel: Transformation preview</p>
<p>Dropdown menu: [None | Log | Square root | Polynomial (degree 2) | Polynomial (degree 3)] When selected, shows histogram of transformed X Summary stats update Shape description updates: “Log transform makes distribution more symmetric”</p>
<p>Interactive scatter plot below: Shows Y vs X, with transformation applied to X-axis in real-time</p>
<p>Original scale markers remain visible (secondary axis) Overlay a smoothed trend line Text updates: “See how log-transform makes the relationship more linear?”</p>
<p>Guidance text: “GLMs assume the relationship between predictors and the link-transformed outcome is linear. Transforming predictors can help achieve this. However, interpretation becomes harder.” “Why transform?” expandable section:</p>
<p>Linearise relationships Handle skewness Make effects multiplicative (log) vs additive (raw) Reduce influence of outliers</p>
<p>Selection mechanism: Radio buttons:</p>
<p>○ Use raw predictor (easier to interpret) ○ Use log(predictor) (more linear relationship) ○ Let me try others… [reveals more options]</p>
<p>Bottom: “Continue with [selected transformation]” button Purpose: Introduce predictor transformations separately from link functions (which come next). Show the visual impact immediately.</p>
<p>Page 5: Fitting Your First Model Title: “Finding the best-fitting line” Context banner: “Model: Binomial GLM with logit link. Predictor: log(length of stay)” Main interaction area: Top half: The Model</p>
<p>Large equation display:</p>
<p>log(π/(1-π)) = β₀ + β₁ × log(length of stay)</p>
<p>Manual sliders for β₀ and β₁ Current values displayed: β₀ = [value], β₁ = [value] Live loss display: “Log-likelihood: -234.56”</p>
<p>Bottom half: The Visualisation Two side-by-side plots:</p>
<p>Data space (left):</p>
<p>Points (jittered binary outcomes) Fitted probability curve (updating live as sliders move) Y-axis: Probability of readmission (0 to 1) X-axis: Log(length of stay)</p>
<p>Link space (right):</p>
<p>Same X-axis Y-axis: log(π/(1-π)) (the linear predictor) Fitted line (straight! because we’re in link space) Observed logit(empirical proportions) as points</p>
<p>Gamification element: “Try to maximise the log-likelihood by moving the sliders! Target: -198.34”</p>
<p>As user moves sliders, if they get close: “You’re getting warmer!” Personal best tracker</p>
<p>Then: Algorithmic fitting section (appears after they’ve played with sliders): Button panel:</p>
<p>“Fit with IRLS (standard GLM)” “Fit with gradient descent” “Fit with Nelder-Mead”</p>
<p>When clicked:</p>
<p>Animation shows β values changing (sliders move automatically) Loss value decreases Iteration counter Small text: “Converged in X iterations”</p>
<p>Results panel (appears after fitting): Coefficients: β₀ = -1.23 (SE: 0.15) β₁ = 0.67 (SE: 0.08)</p>
<p>Interpretation: Each unit increase in log(stay) multiplies the odds of readmission by exp(0.67) = 1.95 Bottom navigation:</p>
<p>“Try a different loss function →” (leads to Page 6) “See diagnostics →” (alternative path)</p>
<p>Purpose: The culmination! They’ve seen the data, chosen the model, prepared predictors, and now they fit. The manual sliders build intuition before algorithmic magic happens.</p>
<p>Page 6 (Optional Advanced): Comparing Loss Functions Title: “Is maximum likelihood special?” Split screen showing three identical model setups side-by-side:</p>
<p>Maximum Likelihood (deviance) Least Squares (on probability scale) Least Absolute Deviation</p>
<p>Each shows:</p>
<p>The fitted curve The coefficient estimates A “badness of fit” metric</p>
<p>Interactive:</p>
<p>Fit all three simultaneously (animated) Compare the resulting curves visually Table comparing β̂ estimates Residual plots for each</p>
<p>Key insight callout: “MLE gives you the most efficient estimates when your distributional assumption (Binomial) is correct. Other loss functions might be more robust but sacrifice efficiency.”</p>
<p>Technical Navigation Structure Progress bar at top of every page showing: Scenario → Data → Model → Predictors → Fitting → [Advanced] Lock mechanism: Can’t proceed until minimum interaction on each page:</p>
<p>Page 1: Must select scenario Page 2: Must interact with plot (hover, toggle view) Page 3: Must read about their model family (tracked by scroll or expansion) Page 4: Must try at least one transformation Page 5: Must either manually adjust sliders OR run an algorithm</p>
<p>React router structure: /scenario /data/:scenarioId /model/:scenarioId /predictors/:scenarioId/:modelFamily /fit/:scenarioId/:modelFamily/:transformation /compare/:scenarioId/:modelFamily/:transformation (optional) State passed between pages via context or URL parameters.</p>
<p>Does this flow feel right? The key pedagogical moves are:</p>
<p>Concrete before abstract (see data before equations) One concept per page (don’t mix link functions and loss functions) Active before passive (manipulate before optimise) Build intuition before automation (manual sliders before algorithms)</p>
<p>What would you modify or emphasise differently?Page 2: I think just a table of the data, paginated, would be sufficient as we may have different variables.Remember potentially transforms of response variables, such as log transforms and/or adding continuity corrections.Also double check about best model for excess zeros. Wouldn’t this potentially require zero inflation not just negative binomial?19 NovYou’re absolutely right on both counts. Page 2 Revision Simple paginated table makes much more sense:</p>
<p>Shows first 20 rows by default Columns: all variables in the dataset Basic pagination controls (Next/Previous, jump to page) Column headers with data type indicators (numeric, binary, count, etc.) Summary row at bottom: N, means/proportions, ranges</p>
<p>Maybe just one summary visualisation option: a dropdown saying “Quick look at…” that lets them pick one variable to see a histogram/bar chart of. But the table is the main event. This is cleaner and scales to multivariate scenarios without cramming everything into one plot.</p>
<p>Excess Zeros - You’re Right I was sloppy. Negative binomial handles overdispersion (variance &gt; mean) but doesn’t specifically model excess zeros. For that you need: Zero-Inflated Models:</p>
<p>Zero-Inflated Poisson (ZIP) Zero-Inflated Negative Binomial (ZINB)</p>
<p>Or alternatively: Hurdle Models:</p>
<p>Two-stage: (1) Binary model for zero vs non-zero, (2) Truncated count model for positive values</p>
<p>So the Page 3 table should be more nuanced: Data TypeIssueModel FamilyWhyCountsOverdispersionNegative BinomialVariance &gt; mean, but zeros still from count processCountsExcess zerosZero-Inflated Poisson/NBTwo processes: structural zeros + count processCountsExcess zeros (alternative)Hurdle ModelSeparate models for zero vs positive For the species abundance scenario, the description should flag: “Many sites have zero organisms—more than a Poisson would predict. This suggests two processes: presence/absence, then abundance given presence.”</p>
<p>Response Transformers Good catch—I’d buried these in the noisemaker component, but they deserve explicit treatment. Let me think about where they fit in the page sequence: Option A: Add them to Page 4 (Predictor Transformers) Rename to “Page 4: Transformers” and split into two sections:</p>
<p>Predictor transformations: h(X) Response transformations: h(Y) [for Gaussian models mainly]</p>
<p>Show that for Gaussian models, transforming Y (e.g., log(Y)) is one approach, but GLMs with a log link are another approach that achieves similar goals whilst keeping Y on its natural scale. Option B: Address them in Page 3 (Model Selection) When discussing Gamma models or Gaussian models, note:</p>
<p>“For positive, right-skewed continuous data, you could: (1) log-transform Y and use Gaussian GLM with identity link, or (2) keep Y untransformed and use Gamma GLM with log link. The latter is often preferable as it handles zeros better (with continuity correction if needed) and respects the variance structure.”</p>
<p>I think Option B is cleaner pedagogically—it positions response transformations as the “old way” that GLMs improve upon, rather than presenting them as separate equal tools. Continuity corrections: These become relevant for:</p>
<p>Log-transforming responses with zeros: log(Y + c) where c is small (e.g., 0.5, 1) Logit-transforming proportions that are exactly 0 or 1: (Y + c)/(n + 2c)</p>
<p>Should probably mention these as a practical note when discussing log/logit links:</p>
<p>“If you have zeros in your response, a log link requires adding a small constant first—but this is arbitrary. Better to use a distribution that naturally handles zeros (Poisson, ZIP) or model the zeros separately (hurdle).”</p>
<p>Does this clean up those issues? The zero-inflation point is particularly important—I should have been more careful distinguishing overdispersion from excess zeros.A key interactive process I’d like to see would look as follows:After selecting the dataset.First get user to select the response column, y. On selecting this it gets pulled to the right hand side of the screenThen ask user to select one or more remaining columns to form the predictor matrix X. These get moved to the left hand side of the screen. There will now be a line going into y, from the leftAnd lines going out of each variable of X, going right.Then once y and X are selected, the next step shown to the user will be to have a switch. These are the transforms h() on predictors. And then a switch for the line going right into y. The transform on response.Then the user gets to select transformer g() and noisemaker f()Show more19 NovOh, this is brilliant! A visual flow diagram that builds up the model specification piece by piece. This makes the entire GLM structure transparent and interactive. Let me sketch this out:</p>
<p>The Interactive Model Builder Interface Stage 1: Select Response Variable Visual layout:</p>
<p>Centre of screen: the full data table (paginated) Instruction banner: “Which variable are you trying to predict or explain?”</p>
<p>Interaction:</p>
<p>User clicks a column header That column slides/animates to the right side of screen Appears in a box labeled Y (Response) Shows: variable name, data type, sample values Quick diagnostic: range, mean/proportion, distribution shape thumbnail</p>
<p>Stage 2: Select Predictor Variables Instruction updates: “Which variables might help explain [response variable name]?” Interaction:</p>
<p>User clicks one or more remaining column headers Each selected column slides/animates to the left side of screen Stack vertically in boxes labeled X₁, X₂, X₃… Each shows: variable name, data type, sample values</p>
<p>Visual connection appears:</p>
<p>Animated lines/arrows from each X box flowing rightward Currently these just point towards the centre (towards Y) The lines are initially thin/grey, labelled “raw”</p>
<p>Stage 3: Transform Predictors Instruction: “Should we transform any predictors before using them?” Visual changes:</p>
<p>Each X box now has a dropdown/switch control appear on it Options: [Raw | Log | √ | x² | x³ | Spline] When user selects a transform:</p>
<p>The box updates: “X₁” → “log(X₁)” The line flowing from it changes colour/thickness A small icon appears on the line showing the transform: h₁() Preview panel shows before/after histogram</p>
<p>Advanced toggle: “Why transform predictors?”</p>
<p>Expandable text about linearity assumptions Mini scatter plot: Y vs X, then Y vs h(X) showing improved linearity</p>
<p>Stage 4: Combine Predictors (Linear Predictor) Instruction: “These predictors combine to form a linear predictor: η = β₀ + β₁h₁(X₁) + β₂h₂(X₂) + …” Visual changes:</p>
<p>The lines from all X boxes converge into a central node This node is labeled η (linear predictor) It’s positioned centre-left of the screen The equation appears inside or below the node Lines are labeled with β₁, β₂, etc.</p>
<p>Optional interaction here:</p>
<p>Click on the η node to see the equation expanded Preview: “This can produce any value from -∞ to +∞”</p>
<p>Stage 5: Link Function (Response Transformer) Instruction: “How should we transform the linear predictor to get predictions for Y?” Visual changes:</p>
<p>A new line flows rightward from η towards Y A transform node appears on this line, labeled g⁻¹() This node has a dropdown:</p>
<p>For binary Y: [Logit | Probit | Complementary log-log] For count Y: [Log | Identity | √] For continuous Y: [Identity | Log | Inverse]</p>
<p>When user selects:</p>
<p>The node updates: “g⁻¹(η) = μ (expected value)” The line changes colour A function visualisation appears:</p>
<p>Small graph showing g⁻¹(η): x-axis is η (-∞ to +∞), y-axis is μ (constrained range) e.g., logit shows sigmoid curve from 0 to 1 e.g., log shows exponential curve from 0 to +∞</p>
<p>Key text callout: “The link function ensures predictions respect constraints: probabilities stay between 0 and 1, counts stay positive, etc.” Stage 6: Noisemaker (Distribution Family) Instruction: “Real data has noise. How are observations scattered around their expected values?” Visual changes:</p>
<p>The line arriving at Y now fans out into multiple possible values A distribution selector appears near the Y box Options depend on Y type:</p>
<p>Binary: [Binomial] (only option, greyed out with explanation) Count: [Poisson | Negative Binomial | Zero-Inflated Poisson] Continuous: [Gaussian | Gamma | Inverse Gaussian]</p>
<p>When user selects:</p>
<p>The Y box updates to show the distribution: “Y ~ Poisson(μ)” A probability function visualisation appears:</p>
<p>For fixed μ value(s), show the PMF/PDF Animate: “If μ = 5, here are possible Y values…” Slider to change μ and watch distribution shift/reshape</p>
<p>Additional parameters:</p>
<p>Some distributions need extras:</p>
<p>Negative Binomial: dispersion parameter θ Gaussian: variance σ²</p>
<p>These appear as additional controls/sliders</p>
<p>Key text callout: “This distribution defines the likelihood function that we’ll maximise to find the best β values.”</p>
<p>Complete Visual Summary At the end, the full flow is visible on screen: [X₁] ─h₁()→ ┐ [X₂] ─h₂()→ ├─→ [η = Xβ] ─g⁻¹()→ [μ] ~<del>f()</del>~&gt; [Y] [X₃] ─h₃()→ ┘ ↓ (observed data) Legend:</p>
<p>h() = predictor transformers (log, sqrt, polynomial, etc.) η = linear predictor (Xβ) g⁻¹() = inverse link function (logit⁻¹, exp, identity) μ = expected value of Y f() = probability distribution (Binomial, Poisson, Gaussian, etc.) Y = observed response data</p>
<p>Interactive Polish Hover behaviours:</p>
<p>Hover over any transform node → see formula and brief explanation Hover over connections → highlight the full path Hover over Y → see summary stats and distribution shape</p>
<p>Collapsible detail levels:</p>
<p>Beginner: just show icon labels on transforms Intermediate: show mathematical notation Advanced: show full equations, variance functions, canonical links</p>
<p>Validation:</p>
<p>If user selects incompatible combinations, gentle warning appears</p>
<p>e.g., “Identity link with Poisson allows negative predictions—are you sure?” Or just grey out illogical combinations</p>
<p>“Show me a valid model” hint button:</p>
<p>If user seems stuck, suggest a conventional choice “For count data, try: Log link + Poisson distribution”</p>
<p>Navigation Flow After completing this model specification: Bottom of screen navigation:</p>
<p>“← Back to data” (can restart) “Continue to fitting →” (proceeds to your slider/optimization page)</p>
<p>State preservation:</p>
<p>All choices encoded in URL or context Can bookmark/share a specific model configuration</p>
<p>Technical Implementation Notes React component structure: jsx<modelbuilder> <datatable> // initially full screen <responseselector onselect="{moveToRight}"> <predictorselector onselect="{moveToLeft}"> <transformcontrols predictortransforms="{...}" linkfunction="{...}" distribution="{...}"> <flowdiagram predictors="{selectedX}" response="{selectedY}" transforms="{transforms}" link="{link}" family="{family}"> </flowdiagram></transformcontrols></predictorselector></responseselector></datatable></modelbuilder> Animation library:</p>
<p>Framer Motion for smooth transitions React Flow or similar for the node-edge diagram D3 for the small function visualisation graphs</p>
<p>The flow diagram itself: Could use React Flow (https://reactflow.dev/):</p>
<p>Nodes: X variables, η, μ, Y Edges: the transformation connections Custom nodes with dropdowns embedded Drag-and-drop could even allow reordering</p>
<p>Does this capture what you’re imagining? The key pedagogical win is making the entire model specification visible as a data flow graph—nothing is hidden in dropdown menus. Every component of the GLM is a visible, interactive element. What would you add or change to this interaction flow?Yes. Please ensure y (observed response) and Y (modelled response) are distinguished. Y is where you placed it. y is a label on observed data which you correctly place below it.This will now help set up for the next page, where we show how the model has to be ‘tuned’, with g() tuned by Beta and f() tuned by alpha (which is sigma in most cases)19 NovExcellent distinction! Let me refine that:</p>
<p>Stage 6 Revised: Noisemaker Visual The complete right-hand side now shows: [η = Xβ] ─g⁻¹()→ [μ] ─f(·|μ,α)→ [Y ~ f(μ, α)] ↓ [y (observed)] Key labels:</p>
<p>μ = Expected value (systematic component output) Y = Random variable following distribution f y = The actual data we observed (shown as points/table below)</p>
<p>Visual representation:</p>
<p>Y box: Shows the distribution family name and random variable: “Y ~ Poisson(μ)” y box (below): Shows actual data table/visualization, labeled “y (observed data)” A dotted/dashed line connects Y to y: “one realization from this distribution”</p>
<p>Interactive element:</p>
<p>Animate multiple draws: “If we could re-run this process, we’d get different y values each time” Show 3-4 simulated datasets briefly appearing in the y box, then return to actual observed data Text: “Our observed y is one possible outcome from Y”</p>
<p>Transition to Next Page: “Tuning the Model” End of model specification page: Summary panel appears: Your model specification: ━━━━━━━━━━━━━━━━━━━━━━</p>
<p>Predictors (X): • log(length_of_stay) • age<br>
• prior_admissions</p>
<p>Linear predictor: η = β₀ + β₁·log(length_of_stay) + β₂·age + β₃·prior_admissions</p>
<p>Link function: μ = g⁻¹(η) = logit⁻¹(η) = exp(η)/(1 + exp(η))</p>
<p>Distribution: Y ~ Binomial(n=1, π=μ) [i.e., Bernoulli]</p>
<p>Observed data: y (1024 observations) Key insight box: “Now we need to find the best values for:</p>
<p>β = (β₀, β₁, β₂, β₃) — these ‘tune’ the systematic part g⁻¹(Xβ) In this case, α is fixed (Binomial has no extra dispersion parameter)</p>
<p>Different data y would suggest different optimal β values. Maximum likelihood finds the β that makes our observed y most probable.” Button: “Continue to fitting →”</p>
<p>Page: Fitting and Tuning Title: “Finding β: Tuning the model to match your data” Page layout: Top Section: Parameter Controls Left side: β parameters (systematic component) Coefficients (β): β₀ (Intercept): [slider: -5 to 5] currently: 0.0 β₁ (log_stay): [slider: -3 to 3] currently: 0.0<br>
β₂ (age): [slider: -0.5 to 0.5] currently: 0.0 β₃ (prior_admissions): [slider: -2 to 2] currently: 0.0 Right side: α parameters (random component) For this Binomial case: Distribution parameters (α): (None for Bernoulli — π is fully determined by μ) But for other examples: For Gaussian: σ² (variance) [slider: 0.1 to 10] For Neg. Binomial: θ (dispersion) [slider: 0.1 to 20]<br>
For Gamma: shape parameter [slider: 0.5 to 10] Key distinction highlighted:</p>
<p>β controls where the expected values μ are (via g⁻¹(Xβ)) α controls how spread out Y is around μ (the noise level)</p>
<p>Middle Section: Live Visualizations Three-panel view: Panel 1: Linear predictor space η = Xβ (for each observation i) Histogram of ηᵢ values Shows: as β changes, this distribution shifts Panel 2: Response space Fitted values μᵢ = g⁻¹(ηᵢ) Scatter: observed y vs.&nbsp;fitted μ For binary: jittered points with fitted probability curve As β changes, the curve reshapes Panel 3: Likelihood landscape Log-likelihood: ℓ(β|y) = Σᵢ log f(yᵢ | μᵢ, α)</p>
<p>Real-time value: ℓ = -234.56</p>
<p>For 2 parameters: contour plot in (β₁, β₂) space Current position marked with crosshairs Target: the peak! Bottom Section: Loss Function Display Formula shown: For Binomial: ℓ(β) = Σᵢ [yᵢ log(μᵢ) + (1-yᵢ) log(1-μᵢ)]</p>
<p>where μᵢ = logit⁻¹(β₀ + β₁x₁ᵢ + β₂x₂ᵢ + β₃x₃ᵢ) Expandable “Why maximize this?”: “This likelihood measures: how probable is our observed data y, given parameters β and α? Maximum likelihood estimation (MLE) finds the β that makes y most probable — the best explanation for what we observed.”</p>
<p>The Tuning Process Manual tuning phase:</p>
<p>User moves β sliders All three panels update in real-time:</p>
<p>η distribution shifts Fitted μ values change, curve reshapes Likelihood value changes Position moves on contour plot</p>
<p>Gamification: “Try to maximize ℓ! Target: -189.23”</p>
<p>Then: Algorithmic tuning Buttons appear:</p>
<p>“Optimize β with IRLS (standard)” “Optimize β with gradient descent” “Optimize (β, α) jointly” [if α exists and isn’t fixed]</p>
<p>When clicked:</p>
<p>Sliders animate to optimal values Iteration counter shows progress Path traced on contour plot Convergence message</p>
<p>Results panel: Converged in 6 iterations!</p>
<p>Optimal parameters: β̂₀ = -2.13 (SE: 0.31) β̂₁ = 0.67 (SE: 0.09) β̂₂ = 0.03 (SE: 0.01) β̂₃ = 0.45 (SE: 0.12)</p>
<p>Maximum log-likelihood: -189.23</p>
<p>Interpretation: - Each additional day of log(stay) multiplies odds of readmission by exp(0.67) = 1.95 - Each additional year of age multiplies odds by exp(0.03) = 1.03 - Each prior admission multiplies odds by exp(0.45) = 1.57</p>
<p>Special Attention: When α Exists For models with dispersion parameters (Gaussian, Negative Binomial, Gamma), show: Two-stage optimization:</p>
<p>“Profile likelihood” approach:</p>
<p>Fix α, optimize β Then fix β, optimize α Iterate until convergence Show this as an animated cycle</p>
<p>Joint optimization:</p>
<p>Optimize (β, α) simultaneously Show 3D likelihood surface (if 1 β + α, i.e., 2D)</p>
<p>Visual distinction:</p>
<p>β sliders are blue (systematic) α sliders are red (random/noise) Likelihood depends on both: ℓ(β, α | y)</p>
<p>Page Flow Summary User journey:</p>
<p>Specify model structure (previous page): h(), g(), f() Understand what needs tuning: β for systematic part, α for random part Manually explore parameter space Let algorithms find optimum Interpret results</p>
<p>Next page options:</p>
<p>“Compare different loss functions →” (your Page 6 idea) “Check model diagnostics →” (residuals, goodness-of-fit) “Try a different model specification ←” (back to revise g() or f())</p>
<p>Does this properly distinguish y vs Y and set up the β vs α tuning distinction clearly? The visual flow from μ → Y → y is crucial for understanding where randomness enters the model.Yes. Please ensure y (observed response) and Y (modelled response) are distinguished. Y is where you placed it. y is a label on observed data which you correctly place below it.This will now help set up for the next page, where we show how the model has to be ‘tuned’, with g() tuned by Beta and f() tuned by alpha (which is sigma in most cases)19 NovPerfect! Let me make sure I have the notation crystal clear:</p>
<p>Precise Notation Structure The flow diagram shows: [X₁] ─h₁()→ ┐ [X₂] ─h₂()→ ├─→ [η = Xβ] ─g⁻¹(·;β)→ [μ] ─f(·;μ,α)→ [Y] [X₃] ─h₃()→ ┘ ↓ [y] (observed) Key distinctions:</p>
<p>g⁻¹(·; β): The inverse link function, parameterized by β</p>
<p>Really it’s g⁻¹(Xβ), so β “tunes” which values of μ we get The link function itself isn’t parameterized, but the linear predictor going into it is</p>
<p>f(·; μ, α): The probability distribution, parameterized by both μ and α</p>
<p>μ comes from g⁻¹(Xβ) — so β indirectly tunes this α is the dispersion/scale parameter (σ for Gaussian, θ for Negative Binomial, etc.)</p>
<p>Y: The random variable — what the model says could happen</p>
<p>Y ~ f(μ, α) Each observation Yᵢ ~ f(μᵢ, α)</p>
<p>y: The actual observed data — what did happen</p>
<p>Specific realization: y = (y₁, y₂, …, yₙ) Shown below Y with arrow indicating “one realization”</p>
<p>Transition Text to Tuning Page At end of model specification: “Your model is now fully specified: Structure defined:</p>
<p>Predictor transformations h(X) Link function g⁻¹(·) Distribution family f(·)</p>
<p>Parameters to tune:</p>
<p>β: tunes g⁻¹(·) — determines where μ lands based on X α: tunes f(·) — determines how spread out Y is around μ</p>
<p>We need to find the β and α values that best explain our observed data y.”</p>
<p>Next Page: “Tuning β and α” Title: “Finding the parameters that fit your data” Opening explanation panel: Your model has two types of parameters:</p>
<p>┌─ β (systematic parameters) ──────────────┐ │ Controls: WHERE the expected values are │ │ Via: μ = g⁻¹(Xβ) │ │ In your model: β = (β₀, β₁, β₂, …) │ └──────────────────────────────────────────┘</p>
<p>┌─ α (dispersion parameter) ───────────────┐ │ Controls: HOW SPREAD OUT observations │ │ are around their expected values│ │ Via: Var(Y) = V(μ) × α │ │ In your model: α = σ² [for Gaussian] │ │ α = θ [for Neg. Binomial] │ └──────────────────────────────────────────┘</p>
<p>Goal: Find (β̂, α̂) that maximize: ℓ(β, α) = Σᵢ log f(yᵢ; μᵢ(β), α)</p>
<p>Interactive Parameter Controls Split layout: Left Panel: β Parameters (Systematic) Linear predictor: η = Xβ Controls the expected values μ = g⁻¹(η)</p>
<p>β₀ (Intercept): [━━━●━━━━━━] 0.00 [-5 ←→ 5]</p>
<p>β₁ (log_stay): [━━━●━━━━━━] 0.00<br>
[-3 ←→ 3]</p>
<p>β₂ (age): [━━━●━━━━━━] 0.00 [-0.5 ←→ 0.5]</p>
<p>Currently: μ̄ = 0.47 (mean fitted probability) Right Panel: α Parameter (Random) For Gaussian: Noise level: Var(Y|μ) = σ²</p>
<p>σ² (variance): [━━━●━━━━━━] 1.00 [0.1 ←→ 10]</p>
<p>Currently: typical deviation = ±1.0 For Negative Binomial: Overdispersion: Var(Y|μ) = μ + μ²/θ</p>
<p>θ (dispersion): [━━━●━━━━━━] 1.00 [0.1 ←→ 20]</p>
<p>Currently: variance is 2× mean (θ=1 → moderate overdispersion) Lower θ → more overdispersion For Binomial (Bernoulli): No extra parameter needed! Var(Y|μ) = μ(1-μ) [variance determined by mean]</p>
<p>α is fixed by the distribution</p>
<p>Visualization Panels (updating in real-time) Panel 1: How β affects μ Left plot: Linear predictor η = Xβ • Histogram of ηᵢ for all observations • As β changes, this distribution shifts/spreads</p>
<p>Right plot: Expected values μ = g⁻¹(η)<br>
• Histogram of μᵢ for all observations • Shows: β controls where μ values concentrate Panel 2: How α affects the spread of Y around μ For a few example observations, show:</p>
<p>μ₁ = 0.3 → Y₁ ~ f(0.3, α) [probability distribution shown] μ₂ = 0.7 → Y₂ ~ f(0.7, α) [probability distribution shown]</p>
<p>As α changes: - Gaussian: curves widen/narrow (σ changes) - Neg. Binomial: variance increases/decreases relative to mean - Gamma: shape of distribution changes</p>
<p>Overlay observed y values to show fit Panel 3: Data vs.&nbsp;Model Scatter plot: observed y vs.&nbsp;fitted μ</p>
<ul>
<li>Perfect fit would have all points on y = μ line</li>
<li>β determines where the fitted values fall</li>
<li>α determines how much scatter around the line we expect</li>
</ul>
<p>Visual: - Points are observed (yᵢ, μᵢ) pairs - Shaded envelope shows ±1 SD based on α - As α increases, envelope widens</p>
<p>Likelihood Display Real-time updating: Log-likelihood: ℓ(β, α | y) = Σᵢ log f(yᵢ; μᵢ(β), α)</p>
<p>Current value: -234.56</p>
<p>This measures: How probable is our observed data y, given parameters β and α?</p>
<p>Goal: Maximize this! (find the β and α that make y most likely) For models with α: Note: Some algorithms fix α first, optimize β, then update α. This is called “REML” or “profile likelihood” when appropriate.</p>
<p>Optimization Controls Manual exploration first:</p>
<p>User adjusts sliders All visualizations update Likelihood value changes “Try to maximize ℓ!”</p>
<p>Then algorithmic: Optimize β (with α fixed): [Button: IRLS] [Button: Newton-Raphson] [Button: Gradient Descent]</p>
<p>Optimize α (with β fixed):<br>
[Button: Profile Likelihood] [Button: REML]</p>
<p>Optimize (β, α) jointly: [Button: Joint Optimization] Animation shows:</p>
<p>Parameters converging Likelihood increasing Iteration count Convergence diagnostics</p>
<p>Results Display Optimization complete!</p>
<p>Systematic parameters (β): β̂₀ = -2.13 (SE: 0.31) β̂₁ = 0.67 (SE: 0.09)<br>
β̂₂ = 0.03 (SE: 0.01)</p>
<p>Dispersion parameter (α): σ̂² = 1.45 (SE: 0.08) [for Gaussian] or θ̂ = 2.34 (SE: 0.42) [for Negative Binomial]</p>
<p>Maximum log-likelihood: -189.23</p>
<p>AIC: 386.46 (penalizes model complexity) BIC: 398.21 (penalizes complexity more heavily)</p>
<p>Does this correctly distinguish:</p>
<p>β tunes g() via the linear predictor Xβ that feeds into g⁻¹ α tunes f() as the dispersion/scale parameter Y is the random variable (model) y is the observed data (reality)</p>
<p>And sets up clearly that we need to find optimal (β̂, α̂) to fit the model to data?</p>


<!-- -->


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>Let's develop a storyboard or interactive tool description for demonstrating how generalised linear models work. What are your initial ideas? We'll 'riff' on this19 NovI'm thinking about what makes GLMs click for people, and I reckon the key insight is seeing how the link function transforms the linear predictor into the response scale. Most people grasp linear regression intuitively, but GLMs add this extra layer of abstraction that can feel opaque.</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>Here are a few directions we could explore:</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The "fitting room" concept</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>Show how different distributions are like different clothing that data needs to wear. You've got count data trying to squeeze into a normal distribution (doesn't fit!), then we try Poisson (perfect fit). The link function is the transformation that makes the linear model's predictions compatible with each distribution's constraints.</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Interactive link function explorer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>A tool where you manipulate a linear predictor (drag sliders for coefficients), and watch in real-time how different link functions (logit, log, identity, probit) transform that straight line into curves on the response scale. Split view: left side shows the linear predictor space, right side shows the transformed predictions with actual data points overlaid.</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>The "constraint satisfaction" narrative</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>Frame it as: "We want to do linear regression, BUT our response variable breaks the rules (negative counts? probabilities outside 0-1?). How do we make predictions that respect the constraints whilst keeping our beloved linear model?" Show the link function as the clever compromise.</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Residual patterns detective</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>Start with someone fitting regular linear regression to inappropriate data (binomial, count, gamma). Show the diagnostic plots looking terrible. Then progressively introduce: "What if we transform the response? What if we change the error distribution? What if we do both systematically?" Build up to the GLM framework as the principled solution.</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Which of these resonates? Or have they sparked a different direction entirely?Let's think how we might develop an interactive page for explaining how GLMs work.&nbsp;Think of three core components:1) Response Transformers: g(.). These transform the response as you suggest.</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>2) Noisemakers: f(.). These allow stochasticity to be represented.</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>3) Predictor transformers: h(.). These transform part of the predictor matrix X so as to make it closer to normally distributed.Could you imagine how an interactive tool could be developed which shows how different types of data can be represented using these three types of component?19 NovThis is a brilliant decomposition! You're essentially separating the systematic component (predictors), the random component (error distribution), and the link between them. Let me sketch out how an interactive tool could work:</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>Core Interface Structure</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>Three-panel layout:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>Panel 1: Data Generator (left side)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>User selects a "data scenario" from dropdown or cards:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>"Hospital readmissions" (binomial)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>"Insurance claims count" (Poisson/negative binomial)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>"Time to equipment failure" (gamma/exponential)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>"Air quality measurements" (Gaussian)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>Underlying truth: you generate data where X → η (linear predictor) → μ (mean) → Y (response)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>Panel 2: Component Workshop (centre, the meat of it)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>Three interactive sections stacked vertically:</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>Predictor Transformers h(X)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>Toggles/dropdowns for each predictor: <span class="co">[</span><span class="ot">Raw | Log | Square root | Polynomial | Spline</span><span class="co">]</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>Live scatter plots showing marginal distributions before/after transformation</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>Maybe a normality test statistic updating in real-time</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>Visual: overlaid density curves showing "how normal is this now?"</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>Response Transformers g(μ)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>Dropdown: <span class="co">[</span><span class="ot">Identity | Log | Logit | Probit | Inverse</span><span class="co">]</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>Visual representation: show the function curve itself</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>Key insight display: "This maps (-∞, ∞) to <span class="co">[</span><span class="ot">a, b</span><span class="co">]</span>" with the actual bounds shown</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>Noisemakers f(Y|μ)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>Distribution family selector: <span class="co">[</span><span class="ot">Gaussian | Poisson | Binomial | Gamma | Neg. Binomial</span><span class="co">]</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>Interactive parameters (where relevant): dispersion, trials for binomial, etc.</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>Visual: show probability mass/density function updating as μ changes</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>Maybe animate: "If μ = 5, here's what Y values look like..."</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>Panel 3: Diagnostic Dashboard (right side)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>Real-time fitting and diagnostics:</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>Deviance residuals vs fitted</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>Q-Q plot</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>Residuals vs linear predictor</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>A "badness of fit" meter (simplified deviance or AIC)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>Coefficient estimates with SEs</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>The Interactive Flow</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>Mode 1: Guided Discovery</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>Present data, deliberately fit wrong model (normal identity link to count data)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>Diagnostics look terrible—patterns everywhere</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>Prompt user: "The problem is <span class="co">[</span><span class="ot">X</span><span class="co">]</span>. Try changing <span class="co">[</span><span class="ot">component Y</span><span class="co">]</span>"</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>When they fix it, diagnostics improve dramatically</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>Positive reinforcement: "Notice how the residual pattern disappeared!"</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>Mode 2: Sandbox Exploration</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>Load any dataset or simulation</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>User experiments freely with all three components</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>Tool shows "conventional choice" badge when they select the standard GLM for that data type</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>But allows weird combinations: "Poisson with identity link—see what happens!"</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>Key Interactive Features</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>Linked brushing:</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>Hover over a data point → see it highlighted across all panels</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>See its contribution to deviance, its residual, where it falls in the predictor space</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>Animation of the data generation process:</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>Step through: X → h(X) → β'h(X) → g⁻¹(β'h(X)) = μ → f(Y|μ) → observed Y</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>Show the transformation at each stage with actual numbers for selected observations</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>"What if?" sliders:</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>Change β coefficients and watch predictions update</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>Change dispersion parameter and see variance in f(.) widen/narrow</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>Watch how changing h(.) affects the linearity assumption</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>Comparison mode:</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>Split screen: fit two different models side-by-side</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>Direct visual comparison of residual plots and fit statistics</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>Technical Implementation Thoughts</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>React components structure:</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;DataScenario&gt;</span> - handles data generation and state</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;TransformerPanel&gt;</span> - the three transformer controls</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;PredictorTransformer&gt;</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;LinkFunction&gt;</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ErrorDistribution&gt;</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;DiagnosticsDashboard&gt;</span> - recharts visualisations</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ModelFitter&gt;</span> - probably calls a WebAssembly-compiled GLM fitter or servers-side R API</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>For actual GLM fitting:</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>You could either:</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>Call a lightweight JavaScript GLM library (glmnet.js if it exists, or roll your own for simple cases)</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>Use WebAssembly to compile R's glm() function</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>Server-side: hit an R/Python API endpoint (Plumber or FastAPI)</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>Given your R preference, option 3 might be cleanest for prototyping: React frontend, Plumber backend doing the heavy lifting.</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>Educational Scaffolding</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>Progressive disclosure:</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>Beginner mode: only show appropriate transformers for each data type</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>Intermediate: show all options but flag inappropriate ones</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>Advanced: complete freedom + show the maths</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>Conceptual annotations:</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>When user selects logit link: "This is for proportions/probabilities. It maps the linear predictor (any real number) to (0,1)"</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>When residual patterns appear: "See this funnel shape? That's heteroskedasticity—variance isn't constant"</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>Does this capture what you're imagining? The key question is whether we want this to be purely demonstrative, or also actually functional for real data analysis?Let's zoom in on the 'what if' slider part for now. A key thing I want to demonstrate is that maximum likelihood is one of many theoretically possible loss functions, though one which can be strongly demonstrated from first principles. It would be good to have options to manually toggle beta and alpha (noisemaker) parameters, but also to select different algorithms and loss functions to do this too. How might that work?19 NovAh, this is excellent! You want to expose the optimisation landscape itself and show that MLE is a choice, albeit a principled one. Let me think through how this could work:</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>Control Panel Structure</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>Manual Controls Section:</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>Sliders for each β coefficient (β₀, β₁, β₂...)</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>Slider(s) for dispersion/scale parameters (φ for quasi-likelihood, overdispersion for NB, etc.)</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>Real-time updates: as you drag, watch predictions and loss function value change</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>Optimisation Section:</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>Two dropdown menus side-by-side:</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Loss Function Selector:</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>Maximum Likelihood (deviance)</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>Least Squares (MSE on response scale)</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>Least Squares on transformed scale (MSE on g(μ) scale)</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>Least Absolute Deviation (L1 loss)</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>Huber loss (robust)</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>Custom: user enters their own function?</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Algorithm Selector:</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>Iteratively Reweighted Least Squares (IRLS) <span class="co">[</span><span class="ot">the standard</span><span class="co">]</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>Newton-Raphson</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>Gradient Descent</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>Nelder-Mead (derivative-free)</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>Coordinate Descent</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>Manual (slider control only)</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>Then an "Optimise" button that runs the selected algorithm with the selected loss.</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>Visual Feedback Components</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Loss Surface Visualisation</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>This is crucial for intuition. For 2 parameters (say β₀ and β₁):</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>Contour plot of the loss function in (β₀, β₁) space</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>Current parameter values shown as a point</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>As algorithm runs, show the trajectory of the optimisation path</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>Different algorithms trace different paths to the minimum</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>For &gt;2 parameters, could show:</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>2D slices through the loss surface (fix all but two parameters)</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>Or parallel coordinates plot showing parameter evolution over iterations</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Loss Function Value Tracker</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>Real-time numeric display: "Current loss: 234.56"</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>Line plot showing loss decreasing over iterations when algorithm runs</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>Compare multiple algorithms: overlaid traces showing convergence speed</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Algorithm Diagnostics Panel</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>When an algorithm is running/has run:</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>Iteration count</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>Convergence status (gradient norm, relative change in loss)</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>For IRLS specifically: show the working weights evolving</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>Step size (for gradient descent variants)</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Split View: Predictions Panel</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>Top: fitted values overlaid on data</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>Bottom: residuals</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>Updates in real-time as β changes (manual or algorithmic)</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>The Interactive Workflow</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>Workflow 1: Manual Exploration</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>User loads data (say, Poisson count data)</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>Sets algorithm to "Manual"</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>Moves β sliders around</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>Watches:</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>Loss function value change</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>Their position move on the contour plot</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>Fitted line move on the data plot</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>Residual patterns shift</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>Tries to minimise loss themselves (gamification!)</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>Then clicks "Optimise with IRLS" to see the algorithm find it instantly</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>Workflow 2: Loss Function Comparison</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>Fit Poisson data with Maximum Likelihood → get β̂_ML</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>Switch loss to "Least Squares" → optimise again → get β̂_LS</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>Display both sets of coefficients side-by-side</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>Show both fitted lines on the same plot</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>Key insight: "See how LS gives more weight to outliers?"</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>Workflow 3: Algorithm Racing</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>Split the contour plot into 3-4 panels, each running a different algorithm simultaneously from the same starting point:</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>IRLS (top-left)</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>Gradient Descent (top-right)</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>Newton-Raphson (bottom-left)</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>Nelder-Mead (bottom-right)</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>Animate them converging at different speeds, different paths. Some might overshoot, some take more iterations.</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>Deep Dive: The Loss Function Maths Display</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>When user hovers over or selects a loss function, show a formula panel:</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>For Maximum Likelihood (Poisson):</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>L(β) = Σᵢ <span class="co">[</span><span class="ot">yᵢ log(μᵢ) - μᵢ - log(yᵢ!)</span><span class="co">]</span></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>where μᵢ = exp(Xᵢβ)</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>Deviance: D = 2Σᵢ <span class="co">[</span><span class="ot">yᵢ log(yᵢ/μᵢ) - (yᵢ - μᵢ)</span><span class="co">]</span></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>For Least Squares:</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>L(β) = Σᵢ (yᵢ - μᵢ)²</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>For Least Squares (link scale):</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>L(β) = Σᵢ (g(yᵢ) - ηᵢ)²</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>where ηᵢ = Xᵢβ</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>Accompanying text: "MLE comes from assuming data are i.i.d. draws from f(y|μ). It's not just convenient—it's what probability theory tells us to maximise."</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>Demonstrating Why MLE is Special</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>Interactive Demonstration:</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>Efficiency comparison:</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>Generate data from known β</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>Fit with MLE vs LS repeatedly (bootstrap/simulation)</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>Show sampling distributions of β̂: MLE should have tighter distribution</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>Display: "MLE is asymptotically efficient—smallest variance among consistent estimators"</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>Consistency under misspecification:</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>Generate overdispersed Poisson (negative binomial really)</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>Fit with Poisson MLE</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>Show: β̂ still consistent! (SE wrong, but estimates okay)</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>Fit with LS: β̂ might be biased</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>The deviance connection:</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>Show that MLE naturally gives you deviance</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>Deviance → likelihood ratio tests → nested model comparisons</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>Other loss functions don't give you this inferential framework</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>Visual: tree of nested models with deviance differences</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>Technical Implementation Details</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>Loss function calculation (in R backend or JS):</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>javascriptconst lossFunctions = {</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>  mle_poisson: (y, mu) =&gt; </span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>    -sum(y.map((yi, i) =&gt; yi * Math.log(mu<span class="co">[</span><span class="ot">i</span><span class="co">]</span>) - mu<span class="co">[</span><span class="ot">i</span><span class="co">]</span>)),</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>  least_squares: (y, mu) =&gt; </span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>    sum(y.map((yi, i) =&gt; Math.pow(yi - mu<span class="co">[</span><span class="ot">i</span><span class="co">]</span>, 2))),</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>  least_squares_link: (y, eta, linkFn) =&gt; </span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>    sum(y.map((yi, i) =&gt; Math.pow(linkFn(yi) - eta<span class="co">[</span><span class="ot">i</span><span class="co">]</span>, 2))),</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>  // etc.</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>Optimisation algorithms:</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>For IRLS, you'd need the working weights and adjusted dependent variable. This probably wants to live in R:</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a>r# Plumber API endpoint</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>#* @post /optimise</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>function(X, y, family, link, loss_fn, algorithm) {</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>  if (loss_fn == "mle" &amp;&amp; algorithm == "irls") {</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>    fit &lt;- glm(y ~ X - 1, family = family)</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>    return(list(</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>      coefficients = coef(fit),</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>      iterations = fit$iter,</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>      converged = fit$converged,</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>      trajectory = fit$trace  # if we store it</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>  # ... other combinations</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>For the contour plot:</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>Pre-compute loss on a grid of (β₀, β₁) values</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>Use Plotly or D3 for interactive contours</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>Overlay the optimisation path as a line with markers at each iteration</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>Pedagogical Sequencing</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>Level 1: Discovery</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>Hide the maths initially</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>Just show: "Different ways to measure fit"</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>Let them see that different loss functions → different β̂</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>Level 2: Understanding</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>Reveal the formulas</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>Show the connection: MLE ↔ assumed distribution</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>Demonstrate efficiency via simulation</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>Level 3: Advanced</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>Show score functions (gradient of log-likelihood)</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>Fisher information</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>Why IRLS works: connection to Newton-Raphson with expected rather than observed Hessian</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a>Does this align with your vision? The key tension I see is between pedagogical clarity (keep it simple) and completeness (show all the options). Perhaps we need user-selectable "modes": Basic, Intermediate, Advanced?To avoid information overload let’s think how we can guide the user one step at a time, through having one page at a time, which cannot be skipped unless interacted with. To start with the first page could just be a list of scenarios, describing types of problem that can be addressed with statistical modelling. The second page would then allow the user to see the data associated with the scenario. The third page would introduce different types of GLM, the kinds of problems they are used for, and as advanced material their likelihood function. The page after that would then describe some predictor transformers. The page after that would then be when the user starts fitting the data to the model.19 NovExcellent! A linear, guided tour structure prevents cognitive overload and builds understanding progressively. Let me sketch out this page-by-page journey:</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a>Page 1: Scenario Selection</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>Title: "What are you trying to understand?"</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>A card-based interface with 5-6 scenarios:</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>Card layout (each shows an icon, title, one-sentence description):</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>Hospital Readmissions</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>"Will patients return within 30 days? Binary outcomes from medical records."</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>Insurance Claims Volume</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>"How many claims will we receive? Count data with no upper limit."</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>Species Abundance</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>"Counting organisms at different sites. Ecology data with excess zeros."</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a>Equipment Lifespan</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>"When will machines fail? Positive continuous data, right-skewed."</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>Crop Yields</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>"Tonnes per hectare under different treatments. Continuous with constant variance."</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>Market Survey Response</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>"How satisfied are customers? Ordinal categories from 1-5."</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>Interaction: User clicks one card. It expands slightly, others fade. A "Continue" button appears.</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>Purpose: Prime them to think about data types and question types before seeing any maths.</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>Page 2: Explore Your Data</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>Title: "Hospital Readmissions: What does the data look like?"</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>Main visual: Large scatter plot or strip plot showing the data</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>X-axis: a key predictor (e.g., "Length of initial stay (days)")</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>Y-axis: binary outcome (0 = no readmission, 1 = readmission)</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>Points jittered vertically for visibility</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>Maybe add a smoother/loess curve overlaid</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a>Side panel: Data summary statistics</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a>N observations</span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>Proportion of 1s vs 0s</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>Range of predictor</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>A few example rows shown in a mini table</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>Interactive elements:</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>Dropdown to switch which predictor is shown (if multivariate)</span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>Toggle: "Show raw data" vs "Show proportion in bins" (bin the x-axis, show success rate per bin)</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>Key text callout:</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a>"Notice: The outcome is binary (0 or 1), but when we group patients by similar characteristics, the readmission rate varies between 0% and 100%. We need a model that respects these boundaries."</span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>Bottom of page: "Continue" button (always visible once they've interacted with the chart)</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>Purpose: Let them see the problem before solving it. Build intuition about what the model needs to capture.</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>Page 3: Choosing Your Model Family</span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>Title: "Different data, different models"</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a>Main content: A matrix/table layout</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a>Data TypeExampleGLM FamilyWhy this worksBinary (0/1)Readmission?Binomial (Logistic)Maps probabilities to whole real lineCountsNumber of claimsPoissonNon-negative integers onlyCounts (overdispersed)Species with many zerosNegative BinomialAllows more variance than PoissonPositive continuousTime to failureGammaPositive values, right-skewedContinuousCrop yieldGaussianSymmetric, unbounded</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a>Your scenario is highlighted (e.g., the Binomial row glows/is emphasised)</span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>Interactive element:</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a>Click on each row to expand it</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a>Expansion shows:</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a>A small plot of the probability/density function shape</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a>The link function (name only at this stage): "logit", "log", "identity"</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a>One-sentence: "Use this when..."</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a>"Show me the maths" toggle (collapsed by default):</span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>When expanded, shows for the highlighted row:</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>For Binomial/Logistic:</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a>Pr(Y = 1 | X) = π</span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>π = g⁻¹(Xβ), where g(π) = log(π/(1-π))  <span class="co">[</span><span class="ot">logit link</span><span class="co">]</span></span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>Likelihood: L(β) = ∏ᵢ πᵢʸⁱ(1-πᵢ)⁽¹⁻ʸⁱ⁾</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>Log-likelihood: ℓ(β) = Σᵢ <span class="co">[</span><span class="ot">yᵢ log(πᵢ) + (1-yᵢ) log(1-πᵢ)</span><span class="co">]</span></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a>Key pedagogical text:</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>"The GLM family determines two things: (1) what values Y can take, and (2) how the variance relates to the mean. Maximum likelihood uses this information to find the best-fitting β."</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>Bottom: "Continue with Binomial GLM" button</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a>Purpose: Connect data type → model family. Plant the seed that likelihood depends on distributional assumptions.</span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a>Page 4: Preparing Your Predictors</span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>Title: "Should we transform the predictors?"</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>Context reminder (small banner at top):</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a>"You're modelling hospital readmissions (binary) using length of stay as a predictor."</span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a>Main visual: Split panel</span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a>Left panel: Current predictor</span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>Histogram of X (length of stay)</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a>Summary stats: mean, SD, range</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a>Shape description: "Right-skewed, most stays are short, a few very long"</span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>Right panel: Transformation preview</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a>Dropdown menu: <span class="co">[</span><span class="ot">None | Log | Square root | Polynomial (degree 2) | Polynomial (degree 3)</span><span class="co">]</span></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a>When selected, shows histogram of transformed X</span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>Summary stats update</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a>Shape description updates: "Log transform makes distribution more symmetric"</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a>Interactive scatter plot below:</span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>Shows Y vs X, with transformation applied to X-axis in real-time</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>Original scale markers remain visible (secondary axis)</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a>Overlay a smoothed trend line</span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a>Text updates: "See how log-transform makes the relationship more linear?"</span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>Guidance text:</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>"GLMs assume the relationship between predictors and the link-transformed outcome is linear. Transforming predictors can help achieve this. However, interpretation becomes harder."</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a>"Why transform?" expandable section:</span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a>Linearise relationships</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a>Handle skewness</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>Make effects multiplicative (log) vs additive (raw)</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a>Reduce influence of outliers</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a>Selection mechanism:</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a>Radio buttons:</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>○ Use raw predictor (easier to interpret)</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a>○ Use log(predictor) (more linear relationship)</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a>○ Let me try others... <span class="co">[</span><span class="ot">reveals more options</span><span class="co">]</span></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a>Bottom: "Continue with <span class="co">[</span><span class="ot">selected transformation</span><span class="co">]</span>" button</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>Purpose: Introduce predictor transformations separately from link functions (which come next). Show the visual impact immediately.</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>Page 5: Fitting Your First Model</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a>Title: "Finding the best-fitting line"</span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>Context banner:</span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>"Model: Binomial GLM with logit link. Predictor: log(length of stay)"</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>Main interaction area:</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a>Top half: The Model</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a>Large equation display:</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a>  log(π/(1-π)) = β₀ + β₁ × log(length of stay)</span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a>Manual sliders for β₀ and β₁</span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a>Current values displayed: β₀ = <span class="co">[</span><span class="ot">value</span><span class="co">]</span>, β₁ = <span class="co">[</span><span class="ot">value</span><span class="co">]</span></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a>Live loss display: "Log-likelihood: -234.56"</span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a>Bottom half: The Visualisation</span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a>Two side-by-side plots:</span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>Data space (left):</span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>Points (jittered binary outcomes)</span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>Fitted probability curve (updating live as sliders move)</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>Y-axis: Probability of readmission (0 to 1)</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>X-axis: Log(length of stay)</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>Link space (right):</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>Same X-axis</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>Y-axis: log(π/(1-π)) (the linear predictor)</span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>Fitted line (straight! because we're in link space)</span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>Observed logit(empirical proportions) as points</span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a>Gamification element:</span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>"Try to maximise the log-likelihood by moving the sliders! Target: -198.34"</span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>As user moves sliders, if they get close: "You're getting warmer!"</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a>Personal best tracker</span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>Then: Algorithmic fitting section (appears after they've played with sliders):</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>Button panel:</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>"Fit with IRLS (standard GLM)"</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>"Fit with gradient descent"</span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>"Fit with Nelder-Mead"</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>When clicked:</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>Animation shows β values changing (sliders move automatically)</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>Loss value decreases</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>Iteration counter</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>Small text: "Converged in X iterations"</span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>Results panel (appears after fitting):</span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a>  β₀ = -1.23 (SE: 0.15)</span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>  β₁ =  0.67 (SE: 0.08)</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>Interpretation:</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a>Each unit increase in log(stay) multiplies the odds </span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>of readmission by exp(0.67) = 1.95</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a>Bottom navigation:</span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>"Try a different loss function →" (leads to Page 6)</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>"See diagnostics →" (alternative path)</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>Purpose: The culmination! They've seen the data, chosen the model, prepared predictors, and now they fit. The manual sliders build intuition before algorithmic magic happens.</span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>Page 6 (Optional Advanced): Comparing Loss Functions</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>Title: "Is maximum likelihood special?"</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>Split screen showing three identical model setups side-by-side:</span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>Maximum Likelihood (deviance)</span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a>Least Squares (on probability scale)</span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a>Least Absolute Deviation</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>Each shows:</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>The fitted curve</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a>The coefficient estimates</span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>A "badness of fit" metric</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a>Interactive:</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a>Fit all three simultaneously (animated)</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a>Compare the resulting curves visually</span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>Table comparing β̂ estimates</span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a>Residual plots for each</span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a>Key insight callout:</span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a>"MLE gives you the most efficient estimates when your distributional assumption (Binomial) is correct. Other loss functions might be more robust but sacrifice efficiency."</span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a>Technical Navigation Structure</span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a>Progress bar at top of every page showing: Scenario → Data → Model → Predictors → Fitting → <span class="co">[</span><span class="ot">Advanced</span><span class="co">]</span></span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a>Lock mechanism: Can't proceed until minimum interaction on each page:</span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>Page 1: Must select scenario</span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a>Page 2: Must interact with plot (hover, toggle view)</span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a>Page 3: Must read about their model family (tracked by scroll or expansion)</span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a>Page 4: Must try at least one transformation</span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a>Page 5: Must either manually adjust sliders OR run an algorithm</span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a>React router structure:</span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a>/scenario</span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a>/data/:scenarioId</span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a>/model/:scenarioId</span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a>/predictors/:scenarioId/:modelFamily</span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a>/fit/:scenarioId/:modelFamily/:transformation</span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a>/compare/:scenarioId/:modelFamily/:transformation (optional)</span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a>State passed between pages via context or URL parameters.</span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a>Does this flow feel right? The key pedagogical moves are:</span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a>Concrete before abstract (see data before equations)</span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a>One concept per page (don't mix link functions and loss functions)</span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a>Active before passive (manipulate before optimise)</span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a>Build intuition before automation (manual sliders before algorithms)</span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a>What would you modify or emphasise differently?Page 2: I think just a table of the data, paginated, would be sufficient as we may have different variables.Remember potentially transforms of response variables, such as log transforms and/or adding continuity corrections.Also double check about best model for excess zeros. Wouldn’t this potentially require zero inflation not just negative binomial?19 NovYou're absolutely right on both counts.</span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a>Page 2 Revision</span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a>Simple paginated table makes much more sense:</span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a>Shows first 20 rows by default</span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a>Columns: all variables in the dataset</span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a>Basic pagination controls (Next/Previous, jump to page)</span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a>Column headers with data type indicators (numeric, binary, count, etc.)</span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a>Summary row at bottom: N, means/proportions, ranges</span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>Maybe just one summary visualisation option: a dropdown saying "Quick look at..." that lets them pick one variable to see a histogram/bar chart of. But the table is the main event.</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a>This is cleaner and scales to multivariate scenarios without cramming everything into one plot.</span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a>Excess Zeros - You're Right</span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>I was sloppy. Negative binomial handles overdispersion (variance &gt; mean) but doesn't specifically model excess zeros. For that you need:</span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a>Zero-Inflated Models:</span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a>Zero-Inflated Poisson (ZIP)</span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a>Zero-Inflated Negative Binomial (ZINB)</span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a>Or alternatively:</span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a>Hurdle Models:</span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a>Two-stage: (1) Binary model for zero vs non-zero, (2) Truncated count model for positive values</span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a>So the Page 3 table should be more nuanced:</span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>Data TypeIssueModel FamilyWhyCountsOverdispersionNegative BinomialVariance &gt; mean, but zeros still from count processCountsExcess zerosZero-Inflated Poisson/NBTwo processes: structural zeros + count processCountsExcess zeros (alternative)Hurdle ModelSeparate models for zero vs positive</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a>For the species abundance scenario, the description should flag: "Many sites have zero organisms—more than a Poisson would predict. This suggests two processes: presence/absence, then abundance given presence."</span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a>Response Transformers</span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a>Good catch—I'd buried these in the noisemaker component, but they deserve explicit treatment. Let me think about where they fit in the page sequence:</span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a>Option A: Add them to Page 4 (Predictor Transformers)</span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a>Rename to "Page 4: Transformers" and split into two sections:</span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a>Predictor transformations: h(X)</span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a>Response transformations: h(Y) <span class="co">[</span><span class="ot">for Gaussian models mainly</span><span class="co">]</span></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a>Show that for Gaussian models, transforming Y (e.g., log(Y)) is one approach, but GLMs with a log link are another approach that achieves similar goals whilst keeping Y on its natural scale.</span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a>Option B: Address them in Page 3 (Model Selection)</span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a>When discussing Gamma models or Gaussian models, note:</span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a>"For positive, right-skewed continuous data, you could: (1) log-transform Y and use Gaussian GLM with identity link, or (2) keep Y untransformed and use Gamma GLM with log link. The latter is often preferable as it handles zeros better (with continuity correction if needed) and respects the variance structure."</span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a>I think Option B is cleaner pedagogically—it positions response transformations as the "old way" that GLMs improve upon, rather than presenting them as separate equal tools.</span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a>Continuity corrections:</span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a>These become relevant for:</span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a>Log-transforming responses with zeros: log(Y + c) where c is small (e.g., 0.5, 1)</span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a>Logit-transforming proportions that are exactly 0 or 1: (Y + c)/(n + 2c)</span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a>Should probably mention these as a practical note when discussing log/logit links:</span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a>"If you have zeros in your response, a log link requires adding a small constant first—but this is arbitrary. Better to use a distribution that naturally handles zeros (Poisson, ZIP) or model the zeros separately (hurdle)."</span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a>Does this clean up those issues? The zero-inflation point is particularly important—I should have been more careful distinguishing overdispersion from excess zeros.A key interactive process I’d like to see would look as follows:After selecting the dataset.First get user to select the response column, y. On selecting this it gets pulled to the right hand side of the screenThen ask user to select one or more remaining columns to form the predictor matrix X. These get moved to the left hand side of the screen. There will now be a line going into y, from the leftAnd lines going out of each variable of X, going right.Then once y and X are selected, the next step shown to the user will be to have a switch. These are the transforms h() on predictors. And then a switch for the line going right into y. The transform on response.Then the user gets to select transformer g() and noisemaker f()Show more19 NovOh, this is brilliant! A visual flow diagram that builds up the model specification piece by piece. This makes the entire GLM structure transparent and interactive. Let me sketch this out:</span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a>The Interactive Model Builder Interface</span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a>Stage 1: Select Response Variable</span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a>Visual layout:</span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a>Centre of screen: the full data table (paginated)</span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a>Instruction banner: "Which variable are you trying to predict or explain?"</span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a>Interaction:</span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a>User clicks a column header</span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a>That column slides/animates to the right side of screen</span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a>Appears in a box labeled Y (Response)</span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a>Shows: variable name, data type, sample values</span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a>Quick diagnostic: range, mean/proportion, distribution shape thumbnail</span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a>Stage 2: Select Predictor Variables</span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a>Instruction updates: "Which variables might help explain <span class="co">[</span><span class="ot">response variable name</span><span class="co">]</span>?"</span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a>Interaction:</span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a>User clicks one or more remaining column headers</span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a>Each selected column slides/animates to the left side of screen</span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a>Stack vertically in boxes labeled X₁, X₂, X₃...</span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a>Each shows: variable name, data type, sample values</span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a>Visual connection appears:</span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a>Animated lines/arrows from each X box flowing rightward</span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a>Currently these just point towards the centre (towards Y)</span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a>The lines are initially thin/grey, labelled "raw"</span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a>Stage 3: Transform Predictors</span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a>Instruction: "Should we transform any predictors before using them?"</span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a>Visual changes:</span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a>Each X box now has a dropdown/switch control appear on it</span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a>Options: <span class="co">[</span><span class="ot">Raw | Log | √ | x² | x³ | Spline</span><span class="co">]</span></span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a>When user selects a transform:</span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a>The box updates: "X₁" → "log(X₁)"</span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a>The line flowing from it changes colour/thickness</span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a>A small icon appears on the line showing the transform: h₁()</span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a>Preview panel shows before/after histogram</span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a>Advanced toggle: "Why transform predictors?"</span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a>Expandable text about linearity assumptions</span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a>Mini scatter plot: Y vs X, then Y vs h(X) showing improved linearity</span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a>Stage 4: Combine Predictors (Linear Predictor)</span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a>Instruction: "These predictors combine to form a linear predictor: η = β₀ + β₁h₁(X₁) + β₂h₂(X₂) + ..."</span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a>Visual changes:</span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a>The lines from all X boxes converge into a central node</span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a>This node is labeled η (linear predictor)</span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a>It's positioned centre-left of the screen</span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a>The equation appears inside or below the node</span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a>Lines are labeled with β₁, β₂, etc.</span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a>Optional interaction here:</span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a>Click on the η node to see the equation expanded</span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a>Preview: "This can produce any value from -∞ to +∞"</span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a>Stage 5: Link Function (Response Transformer)</span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a>Instruction: "How should we transform the linear predictor to get predictions for Y?"</span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a>Visual changes:</span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a>A new line flows rightward from η towards Y</span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a>A transform node appears on this line, labeled g⁻¹()</span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a>This node has a dropdown:</span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a>For binary Y: <span class="co">[</span><span class="ot">Logit | Probit | Complementary log-log</span><span class="co">]</span></span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a>For count Y: <span class="co">[</span><span class="ot">Log | Identity | √</span><span class="co">]</span></span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a>For continuous Y: <span class="co">[</span><span class="ot">Identity | Log | Inverse</span><span class="co">]</span></span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a>When user selects:</span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a>The node updates: "g⁻¹(η) = μ (expected value)"</span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a>The line changes colour</span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a>A function visualisation appears:</span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a>Small graph showing g⁻¹(η): x-axis is η (-∞ to +∞), y-axis is μ (constrained range)</span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a>e.g., logit shows sigmoid curve from 0 to 1</span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a>e.g., log shows exponential curve from 0 to +∞</span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a>Key text callout:</span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a>"The link function ensures predictions respect constraints: probabilities stay between 0 and 1, counts stay positive, etc."</span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a>Stage 6: Noisemaker (Distribution Family)</span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a>Instruction: "Real data has noise. How are observations scattered around their expected values?"</span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a>Visual changes:</span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a>The line arriving at Y now fans out into multiple possible values</span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a>A distribution selector appears near the Y box</span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a>Options depend on Y type:</span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a>Binary: <span class="co">[</span><span class="ot">Binomial</span><span class="co">]</span> (only option, greyed out with explanation)</span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a>Count: <span class="co">[</span><span class="ot">Poisson | Negative Binomial | Zero-Inflated Poisson</span><span class="co">]</span></span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a>Continuous: <span class="co">[</span><span class="ot">Gaussian | Gamma | Inverse Gaussian</span><span class="co">]</span></span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a>When user selects:</span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a>The Y box updates to show the distribution: "Y ~ Poisson(μ)"</span>
<span id="cb1-737"><a href="#cb1-737" aria-hidden="true" tabindex="-1"></a>A probability function visualisation appears:</span>
<span id="cb1-738"><a href="#cb1-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-739"><a href="#cb1-739" aria-hidden="true" tabindex="-1"></a>For fixed μ value(s), show the PMF/PDF</span>
<span id="cb1-740"><a href="#cb1-740" aria-hidden="true" tabindex="-1"></a>Animate: "If μ = 5, here are possible Y values..."</span>
<span id="cb1-741"><a href="#cb1-741" aria-hidden="true" tabindex="-1"></a>Slider to change μ and watch distribution shift/reshape</span>
<span id="cb1-742"><a href="#cb1-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-743"><a href="#cb1-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-744"><a href="#cb1-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-745"><a href="#cb1-745" aria-hidden="true" tabindex="-1"></a>Additional parameters:</span>
<span id="cb1-746"><a href="#cb1-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-747"><a href="#cb1-747" aria-hidden="true" tabindex="-1"></a>Some distributions need extras:</span>
<span id="cb1-748"><a href="#cb1-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-749"><a href="#cb1-749" aria-hidden="true" tabindex="-1"></a>Negative Binomial: dispersion parameter θ</span>
<span id="cb1-750"><a href="#cb1-750" aria-hidden="true" tabindex="-1"></a>Gaussian: variance σ²</span>
<span id="cb1-751"><a href="#cb1-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-752"><a href="#cb1-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-753"><a href="#cb1-753" aria-hidden="true" tabindex="-1"></a>These appear as additional controls/sliders</span>
<span id="cb1-754"><a href="#cb1-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-755"><a href="#cb1-755" aria-hidden="true" tabindex="-1"></a>Key text callout:</span>
<span id="cb1-756"><a href="#cb1-756" aria-hidden="true" tabindex="-1"></a>"This distribution defines the likelihood function that we'll maximise to find the best β values."</span>
<span id="cb1-757"><a href="#cb1-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-758"><a href="#cb1-758" aria-hidden="true" tabindex="-1"></a>Complete Visual Summary</span>
<span id="cb1-759"><a href="#cb1-759" aria-hidden="true" tabindex="-1"></a>At the end, the full flow is visible on screen:</span>
<span id="cb1-760"><a href="#cb1-760" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">X₁</span><span class="co">]</span> ─h₁()→ ┐</span>
<span id="cb1-761"><a href="#cb1-761" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">X₂</span><span class="co">]</span> ─h₂()→ ├─→ <span class="co">[</span><span class="ot">η = Xβ</span><span class="co">]</span> ─g⁻¹()→ <span class="co">[</span><span class="ot">μ</span><span class="co">]</span> ~~~f()~~~&gt; <span class="co">[</span><span class="ot">Y</span><span class="co">]</span></span>
<span id="cb1-762"><a href="#cb1-762" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">X₃</span><span class="co">]</span> ─h₃()→ ┘                              ↓</span>
<span id="cb1-763"><a href="#cb1-763" aria-hidden="true" tabindex="-1"></a>                                      (observed data)</span>
<span id="cb1-764"><a href="#cb1-764" aria-hidden="true" tabindex="-1"></a>Legend:</span>
<span id="cb1-765"><a href="#cb1-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-766"><a href="#cb1-766" aria-hidden="true" tabindex="-1"></a>h() = predictor transformers (log, sqrt, polynomial, etc.)</span>
<span id="cb1-767"><a href="#cb1-767" aria-hidden="true" tabindex="-1"></a>η = linear predictor (Xβ)</span>
<span id="cb1-768"><a href="#cb1-768" aria-hidden="true" tabindex="-1"></a>g⁻¹() = inverse link function (logit⁻¹, exp, identity)</span>
<span id="cb1-769"><a href="#cb1-769" aria-hidden="true" tabindex="-1"></a>μ = expected value of Y</span>
<span id="cb1-770"><a href="#cb1-770" aria-hidden="true" tabindex="-1"></a>f() = probability distribution (Binomial, Poisson, Gaussian, etc.)</span>
<span id="cb1-771"><a href="#cb1-771" aria-hidden="true" tabindex="-1"></a>Y = observed response data</span>
<span id="cb1-772"><a href="#cb1-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-773"><a href="#cb1-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-774"><a href="#cb1-774" aria-hidden="true" tabindex="-1"></a>Interactive Polish</span>
<span id="cb1-775"><a href="#cb1-775" aria-hidden="true" tabindex="-1"></a>Hover behaviours:</span>
<span id="cb1-776"><a href="#cb1-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-777"><a href="#cb1-777" aria-hidden="true" tabindex="-1"></a>Hover over any transform node → see formula and brief explanation</span>
<span id="cb1-778"><a href="#cb1-778" aria-hidden="true" tabindex="-1"></a>Hover over connections → highlight the full path</span>
<span id="cb1-779"><a href="#cb1-779" aria-hidden="true" tabindex="-1"></a>Hover over Y → see summary stats and distribution shape</span>
<span id="cb1-780"><a href="#cb1-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-781"><a href="#cb1-781" aria-hidden="true" tabindex="-1"></a>Collapsible detail levels:</span>
<span id="cb1-782"><a href="#cb1-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-783"><a href="#cb1-783" aria-hidden="true" tabindex="-1"></a>Beginner: just show icon labels on transforms</span>
<span id="cb1-784"><a href="#cb1-784" aria-hidden="true" tabindex="-1"></a>Intermediate: show mathematical notation</span>
<span id="cb1-785"><a href="#cb1-785" aria-hidden="true" tabindex="-1"></a>Advanced: show full equations, variance functions, canonical links</span>
<span id="cb1-786"><a href="#cb1-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-787"><a href="#cb1-787" aria-hidden="true" tabindex="-1"></a>Validation:</span>
<span id="cb1-788"><a href="#cb1-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-789"><a href="#cb1-789" aria-hidden="true" tabindex="-1"></a>If user selects incompatible combinations, gentle warning appears</span>
<span id="cb1-790"><a href="#cb1-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-791"><a href="#cb1-791" aria-hidden="true" tabindex="-1"></a>e.g., "Identity link with Poisson allows negative predictions—are you sure?"</span>
<span id="cb1-792"><a href="#cb1-792" aria-hidden="true" tabindex="-1"></a>Or just grey out illogical combinations</span>
<span id="cb1-793"><a href="#cb1-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-794"><a href="#cb1-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-795"><a href="#cb1-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-796"><a href="#cb1-796" aria-hidden="true" tabindex="-1"></a>"Show me a valid model" hint button:</span>
<span id="cb1-797"><a href="#cb1-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-798"><a href="#cb1-798" aria-hidden="true" tabindex="-1"></a>If user seems stuck, suggest a conventional choice</span>
<span id="cb1-799"><a href="#cb1-799" aria-hidden="true" tabindex="-1"></a>"For count data, try: Log link + Poisson distribution"</span>
<span id="cb1-800"><a href="#cb1-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-801"><a href="#cb1-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-802"><a href="#cb1-802" aria-hidden="true" tabindex="-1"></a>Navigation Flow</span>
<span id="cb1-803"><a href="#cb1-803" aria-hidden="true" tabindex="-1"></a>After completing this model specification:</span>
<span id="cb1-804"><a href="#cb1-804" aria-hidden="true" tabindex="-1"></a>Bottom of screen navigation:</span>
<span id="cb1-805"><a href="#cb1-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-806"><a href="#cb1-806" aria-hidden="true" tabindex="-1"></a>"← Back to data" (can restart)</span>
<span id="cb1-807"><a href="#cb1-807" aria-hidden="true" tabindex="-1"></a>"Continue to fitting →" (proceeds to your slider/optimization page)</span>
<span id="cb1-808"><a href="#cb1-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-809"><a href="#cb1-809" aria-hidden="true" tabindex="-1"></a>State preservation:</span>
<span id="cb1-810"><a href="#cb1-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-811"><a href="#cb1-811" aria-hidden="true" tabindex="-1"></a>All choices encoded in URL or context</span>
<span id="cb1-812"><a href="#cb1-812" aria-hidden="true" tabindex="-1"></a>Can bookmark/share a specific model configuration</span>
<span id="cb1-813"><a href="#cb1-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-814"><a href="#cb1-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-815"><a href="#cb1-815" aria-hidden="true" tabindex="-1"></a>Technical Implementation Notes</span>
<span id="cb1-816"><a href="#cb1-816" aria-hidden="true" tabindex="-1"></a>React component structure:</span>
<span id="cb1-817"><a href="#cb1-817" aria-hidden="true" tabindex="-1"></a>jsx<span class="kw">&lt;ModelBuilder&gt;</span></span>
<span id="cb1-818"><a href="#cb1-818" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;DataTable</span> <span class="kw">/&gt;</span> // initially full screen</span>
<span id="cb1-819"><a href="#cb1-819" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;ResponseSelector</span> <span class="er">onSelect</span><span class="ot">=</span><span class="st">{moveToRight}</span> <span class="kw">/&gt;</span></span>
<span id="cb1-820"><a href="#cb1-820" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;PredictorSelector</span> <span class="er">onSelect</span><span class="ot">=</span><span class="st">{moveToLeft}</span> <span class="kw">/&gt;</span></span>
<span id="cb1-821"><a href="#cb1-821" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;TransformControls</span> </span>
<span id="cb1-822"><a href="#cb1-822" aria-hidden="true" tabindex="-1"></a><span class="ot">    predictorTransforms=</span><span class="st">{...}</span></span>
<span id="cb1-823"><a href="#cb1-823" aria-hidden="true" tabindex="-1"></a><span class="ot">    linkFunction=</span><span class="st">{...}</span></span>
<span id="cb1-824"><a href="#cb1-824" aria-hidden="true" tabindex="-1"></a><span class="ot">    distribution=</span><span class="st">{...}</span></span>
<span id="cb1-825"><a href="#cb1-825" aria-hidden="true" tabindex="-1"></a>  <span class="kw">/&gt;</span></span>
<span id="cb1-826"><a href="#cb1-826" aria-hidden="true" tabindex="-1"></a>  <span class="kw">&lt;FlowDiagram</span> </span>
<span id="cb1-827"><a href="#cb1-827" aria-hidden="true" tabindex="-1"></a><span class="ot">    predictors=</span><span class="st">{selectedX}</span></span>
<span id="cb1-828"><a href="#cb1-828" aria-hidden="true" tabindex="-1"></a><span class="ot">    response=</span><span class="st">{selectedY}</span></span>
<span id="cb1-829"><a href="#cb1-829" aria-hidden="true" tabindex="-1"></a><span class="ot">    transforms=</span><span class="st">{transforms}</span></span>
<span id="cb1-830"><a href="#cb1-830" aria-hidden="true" tabindex="-1"></a><span class="ot">    link=</span><span class="st">{link}</span></span>
<span id="cb1-831"><a href="#cb1-831" aria-hidden="true" tabindex="-1"></a><span class="ot">    family=</span><span class="st">{family}</span></span>
<span id="cb1-832"><a href="#cb1-832" aria-hidden="true" tabindex="-1"></a>  <span class="kw">/&gt;</span></span>
<span id="cb1-833"><a href="#cb1-833" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ModelBuilder&gt;</span></span>
<span id="cb1-834"><a href="#cb1-834" aria-hidden="true" tabindex="-1"></a>Animation library:</span>
<span id="cb1-835"><a href="#cb1-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-836"><a href="#cb1-836" aria-hidden="true" tabindex="-1"></a>Framer Motion for smooth transitions</span>
<span id="cb1-837"><a href="#cb1-837" aria-hidden="true" tabindex="-1"></a>React Flow or similar for the node-edge diagram</span>
<span id="cb1-838"><a href="#cb1-838" aria-hidden="true" tabindex="-1"></a>D3 for the small function visualisation graphs</span>
<span id="cb1-839"><a href="#cb1-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-840"><a href="#cb1-840" aria-hidden="true" tabindex="-1"></a>The flow diagram itself:</span>
<span id="cb1-841"><a href="#cb1-841" aria-hidden="true" tabindex="-1"></a>Could use React Flow (https://reactflow.dev/):</span>
<span id="cb1-842"><a href="#cb1-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-843"><a href="#cb1-843" aria-hidden="true" tabindex="-1"></a>Nodes: X variables, η, μ, Y</span>
<span id="cb1-844"><a href="#cb1-844" aria-hidden="true" tabindex="-1"></a>Edges: the transformation connections</span>
<span id="cb1-845"><a href="#cb1-845" aria-hidden="true" tabindex="-1"></a>Custom nodes with dropdowns embedded</span>
<span id="cb1-846"><a href="#cb1-846" aria-hidden="true" tabindex="-1"></a>Drag-and-drop could even allow reordering</span>
<span id="cb1-847"><a href="#cb1-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-848"><a href="#cb1-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-849"><a href="#cb1-849" aria-hidden="true" tabindex="-1"></a>Does this capture what you're imagining? The key pedagogical win is making the entire model specification visible as a data flow graph—nothing is hidden in dropdown menus. Every component of the GLM is a visible, interactive element.</span>
<span id="cb1-850"><a href="#cb1-850" aria-hidden="true" tabindex="-1"></a>What would you add or change to this interaction flow?Yes. Please ensure y (observed response) and Y (modelled response) are distinguished. Y is where you placed it. y is a label on observed data which you correctly place below it.This will now help set up for the next page, where we show how the model has to be ‘tuned’, with g() tuned by Beta and f() tuned by alpha (which is sigma in most cases)19 NovExcellent distinction! Let me refine that:</span>
<span id="cb1-851"><a href="#cb1-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-852"><a href="#cb1-852" aria-hidden="true" tabindex="-1"></a>Stage 6 Revised: Noisemaker Visual</span>
<span id="cb1-853"><a href="#cb1-853" aria-hidden="true" tabindex="-1"></a>The complete right-hand side now shows:</span>
<span id="cb1-854"><a href="#cb1-854" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">η = Xβ</span><span class="co">]</span> ─g⁻¹()→ <span class="co">[</span><span class="ot">μ</span><span class="co">]</span> ─f(·|μ,α)→ <span class="co">[</span><span class="ot">Y ~ f(μ, α)</span><span class="co">]</span></span>
<span id="cb1-855"><a href="#cb1-855" aria-hidden="true" tabindex="-1"></a>                              ↓</span>
<span id="cb1-856"><a href="#cb1-856" aria-hidden="true" tabindex="-1"></a>                         <span class="co">[</span><span class="ot">y (observed)</span><span class="co">]</span></span>
<span id="cb1-857"><a href="#cb1-857" aria-hidden="true" tabindex="-1"></a>Key labels:</span>
<span id="cb1-858"><a href="#cb1-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-859"><a href="#cb1-859" aria-hidden="true" tabindex="-1"></a>μ = Expected value (systematic component output)</span>
<span id="cb1-860"><a href="#cb1-860" aria-hidden="true" tabindex="-1"></a>Y = Random variable following distribution f</span>
<span id="cb1-861"><a href="#cb1-861" aria-hidden="true" tabindex="-1"></a>y = The actual data we observed (shown as points/table below)</span>
<span id="cb1-862"><a href="#cb1-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-863"><a href="#cb1-863" aria-hidden="true" tabindex="-1"></a>Visual representation:</span>
<span id="cb1-864"><a href="#cb1-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-865"><a href="#cb1-865" aria-hidden="true" tabindex="-1"></a>Y box: Shows the distribution family name and random variable: "Y ~ Poisson(μ)"</span>
<span id="cb1-866"><a href="#cb1-866" aria-hidden="true" tabindex="-1"></a>y box (below): Shows actual data table/visualization, labeled "y (observed data)"</span>
<span id="cb1-867"><a href="#cb1-867" aria-hidden="true" tabindex="-1"></a>A dotted/dashed line connects Y to y: "one realization from this distribution"</span>
<span id="cb1-868"><a href="#cb1-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-869"><a href="#cb1-869" aria-hidden="true" tabindex="-1"></a>Interactive element:</span>
<span id="cb1-870"><a href="#cb1-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-871"><a href="#cb1-871" aria-hidden="true" tabindex="-1"></a>Animate multiple draws: "If we could re-run this process, we'd get different y values each time"</span>
<span id="cb1-872"><a href="#cb1-872" aria-hidden="true" tabindex="-1"></a>Show 3-4 simulated datasets briefly appearing in the y box, then return to actual observed data</span>
<span id="cb1-873"><a href="#cb1-873" aria-hidden="true" tabindex="-1"></a>Text: "Our observed y is one possible outcome from Y"</span>
<span id="cb1-874"><a href="#cb1-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-875"><a href="#cb1-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-876"><a href="#cb1-876" aria-hidden="true" tabindex="-1"></a>Transition to Next Page: "Tuning the Model"</span>
<span id="cb1-877"><a href="#cb1-877" aria-hidden="true" tabindex="-1"></a>End of model specification page:</span>
<span id="cb1-878"><a href="#cb1-878" aria-hidden="true" tabindex="-1"></a>Summary panel appears:</span>
<span id="cb1-879"><a href="#cb1-879" aria-hidden="true" tabindex="-1"></a>Your model specification:</span>
<span id="cb1-880"><a href="#cb1-880" aria-hidden="true" tabindex="-1"></a>━━━━━━━━━━━━━━━━━━━━━━</span>
<span id="cb1-881"><a href="#cb1-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-882"><a href="#cb1-882" aria-hidden="true" tabindex="-1"></a>Predictors (X):</span>
<span id="cb1-883"><a href="#cb1-883" aria-hidden="true" tabindex="-1"></a>  • log(length_of_stay)</span>
<span id="cb1-884"><a href="#cb1-884" aria-hidden="true" tabindex="-1"></a>  • age  </span>
<span id="cb1-885"><a href="#cb1-885" aria-hidden="true" tabindex="-1"></a>  • prior_admissions</span>
<span id="cb1-886"><a href="#cb1-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-887"><a href="#cb1-887" aria-hidden="true" tabindex="-1"></a>Linear predictor:</span>
<span id="cb1-888"><a href="#cb1-888" aria-hidden="true" tabindex="-1"></a>  η = β₀ + β₁·log(length_of_stay) + β₂·age + β₃·prior_admissions</span>
<span id="cb1-889"><a href="#cb1-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-890"><a href="#cb1-890" aria-hidden="true" tabindex="-1"></a>Link function:</span>
<span id="cb1-891"><a href="#cb1-891" aria-hidden="true" tabindex="-1"></a>  μ = g⁻¹(η) = logit⁻¹(η) = exp(η)/(1 + exp(η))</span>
<span id="cb1-892"><a href="#cb1-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-893"><a href="#cb1-893" aria-hidden="true" tabindex="-1"></a>Distribution:</span>
<span id="cb1-894"><a href="#cb1-894" aria-hidden="true" tabindex="-1"></a>  Y ~ Binomial(n=1, π=μ)  <span class="co">[</span><span class="ot">i.e., Bernoulli</span><span class="co">]</span></span>
<span id="cb1-895"><a href="#cb1-895" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-896"><a href="#cb1-896" aria-hidden="true" tabindex="-1"></a>Observed data: y (1024 observations)</span>
<span id="cb1-897"><a href="#cb1-897" aria-hidden="true" tabindex="-1"></a>Key insight box:</span>
<span id="cb1-898"><a href="#cb1-898" aria-hidden="true" tabindex="-1"></a>"Now we need to find the best values for:</span>
<span id="cb1-899"><a href="#cb1-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-900"><a href="#cb1-900" aria-hidden="true" tabindex="-1"></a>β = (β₀, β₁, β₂, β₃) — these 'tune' the systematic part g⁻¹(Xβ)</span>
<span id="cb1-901"><a href="#cb1-901" aria-hidden="true" tabindex="-1"></a>In this case, α is fixed (Binomial has no extra dispersion parameter)</span>
<span id="cb1-902"><a href="#cb1-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-903"><a href="#cb1-903" aria-hidden="true" tabindex="-1"></a>Different data y would suggest different optimal β values. Maximum likelihood finds the β that makes our observed y most probable."</span>
<span id="cb1-904"><a href="#cb1-904" aria-hidden="true" tabindex="-1"></a>Button: "Continue to fitting →"</span>
<span id="cb1-905"><a href="#cb1-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-906"><a href="#cb1-906" aria-hidden="true" tabindex="-1"></a>Page: Fitting and Tuning</span>
<span id="cb1-907"><a href="#cb1-907" aria-hidden="true" tabindex="-1"></a>Title: "Finding β: Tuning the model to match your data"</span>
<span id="cb1-908"><a href="#cb1-908" aria-hidden="true" tabindex="-1"></a>Page layout:</span>
<span id="cb1-909"><a href="#cb1-909" aria-hidden="true" tabindex="-1"></a>Top Section: Parameter Controls</span>
<span id="cb1-910"><a href="#cb1-910" aria-hidden="true" tabindex="-1"></a>Left side: β parameters (systematic component)</span>
<span id="cb1-911"><a href="#cb1-911" aria-hidden="true" tabindex="-1"></a>Coefficients (β):</span>
<span id="cb1-912"><a href="#cb1-912" aria-hidden="true" tabindex="-1"></a>  β₀ (Intercept):        <span class="co">[</span><span class="ot">slider: -5 to 5</span><span class="co">]</span>  currently: 0.0</span>
<span id="cb1-913"><a href="#cb1-913" aria-hidden="true" tabindex="-1"></a>  β₁ (log_stay):         <span class="co">[</span><span class="ot">slider: -3 to 3</span><span class="co">]</span>  currently: 0.0  </span>
<span id="cb1-914"><a href="#cb1-914" aria-hidden="true" tabindex="-1"></a>  β₂ (age):              <span class="co">[</span><span class="ot">slider: -0.5 to 0.5</span><span class="co">]</span> currently: 0.0</span>
<span id="cb1-915"><a href="#cb1-915" aria-hidden="true" tabindex="-1"></a>  β₃ (prior_admissions): <span class="co">[</span><span class="ot">slider: -2 to 2</span><span class="co">]</span>  currently: 0.0</span>
<span id="cb1-916"><a href="#cb1-916" aria-hidden="true" tabindex="-1"></a>Right side: α parameters (random component)</span>
<span id="cb1-917"><a href="#cb1-917" aria-hidden="true" tabindex="-1"></a>For this Binomial case:</span>
<span id="cb1-918"><a href="#cb1-918" aria-hidden="true" tabindex="-1"></a>Distribution parameters (α):</span>
<span id="cb1-919"><a href="#cb1-919" aria-hidden="true" tabindex="-1"></a>  (None for Bernoulli — π is fully determined by μ)</span>
<span id="cb1-920"><a href="#cb1-920" aria-hidden="true" tabindex="-1"></a>But for other examples:</span>
<span id="cb1-921"><a href="#cb1-921" aria-hidden="true" tabindex="-1"></a>For Gaussian: σ² (variance)     <span class="co">[</span><span class="ot">slider: 0.1 to 10</span><span class="co">]</span></span>
<span id="cb1-922"><a href="#cb1-922" aria-hidden="true" tabindex="-1"></a>For Neg. Binomial: θ (dispersion) <span class="co">[</span><span class="ot">slider: 0.1 to 20</span><span class="co">]</span>  </span>
<span id="cb1-923"><a href="#cb1-923" aria-hidden="true" tabindex="-1"></a>For Gamma: shape parameter      <span class="co">[</span><span class="ot">slider: 0.5 to 10</span><span class="co">]</span></span>
<span id="cb1-924"><a href="#cb1-924" aria-hidden="true" tabindex="-1"></a>Key distinction highlighted:</span>
<span id="cb1-925"><a href="#cb1-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-926"><a href="#cb1-926" aria-hidden="true" tabindex="-1"></a>β controls where the expected values μ are (via g⁻¹(Xβ))</span>
<span id="cb1-927"><a href="#cb1-927" aria-hidden="true" tabindex="-1"></a>α controls how spread out Y is around μ (the noise level)</span>
<span id="cb1-928"><a href="#cb1-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-929"><a href="#cb1-929" aria-hidden="true" tabindex="-1"></a>Middle Section: Live Visualizations</span>
<span id="cb1-930"><a href="#cb1-930" aria-hidden="true" tabindex="-1"></a>Three-panel view:</span>
<span id="cb1-931"><a href="#cb1-931" aria-hidden="true" tabindex="-1"></a>Panel 1: Linear predictor space</span>
<span id="cb1-932"><a href="#cb1-932" aria-hidden="true" tabindex="-1"></a>η = Xβ (for each observation i)</span>
<span id="cb1-933"><a href="#cb1-933" aria-hidden="true" tabindex="-1"></a>Histogram of ηᵢ values</span>
<span id="cb1-934"><a href="#cb1-934" aria-hidden="true" tabindex="-1"></a>Shows: as β changes, this distribution shifts</span>
<span id="cb1-935"><a href="#cb1-935" aria-hidden="true" tabindex="-1"></a>Panel 2: Response space</span>
<span id="cb1-936"><a href="#cb1-936" aria-hidden="true" tabindex="-1"></a>Fitted values μᵢ = g⁻¹(ηᵢ)</span>
<span id="cb1-937"><a href="#cb1-937" aria-hidden="true" tabindex="-1"></a>Scatter: observed y vs. fitted μ</span>
<span id="cb1-938"><a href="#cb1-938" aria-hidden="true" tabindex="-1"></a>For binary: jittered points with fitted probability curve</span>
<span id="cb1-939"><a href="#cb1-939" aria-hidden="true" tabindex="-1"></a>As β changes, the curve reshapes</span>
<span id="cb1-940"><a href="#cb1-940" aria-hidden="true" tabindex="-1"></a>Panel 3: Likelihood landscape</span>
<span id="cb1-941"><a href="#cb1-941" aria-hidden="true" tabindex="-1"></a>Log-likelihood: ℓ(β|y) = Σᵢ log f(yᵢ | μᵢ, α)</span>
<span id="cb1-942"><a href="#cb1-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-943"><a href="#cb1-943" aria-hidden="true" tabindex="-1"></a>Real-time value: ℓ = -234.56</span>
<span id="cb1-944"><a href="#cb1-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-945"><a href="#cb1-945" aria-hidden="true" tabindex="-1"></a>For 2 parameters: contour plot in (β₁, β₂) space</span>
<span id="cb1-946"><a href="#cb1-946" aria-hidden="true" tabindex="-1"></a>Current position marked with crosshairs</span>
<span id="cb1-947"><a href="#cb1-947" aria-hidden="true" tabindex="-1"></a>Target: the peak!</span>
<span id="cb1-948"><a href="#cb1-948" aria-hidden="true" tabindex="-1"></a>Bottom Section: Loss Function Display</span>
<span id="cb1-949"><a href="#cb1-949" aria-hidden="true" tabindex="-1"></a>Formula shown:</span>
<span id="cb1-950"><a href="#cb1-950" aria-hidden="true" tabindex="-1"></a>For Binomial:</span>
<span id="cb1-951"><a href="#cb1-951" aria-hidden="true" tabindex="-1"></a>ℓ(β) = Σᵢ <span class="co">[</span><span class="ot">yᵢ log(μᵢ) + (1-yᵢ) log(1-μᵢ)</span><span class="co">]</span></span>
<span id="cb1-952"><a href="#cb1-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-953"><a href="#cb1-953" aria-hidden="true" tabindex="-1"></a>where μᵢ = logit⁻¹(β₀ + β₁x₁ᵢ + β₂x₂ᵢ + β₃x₃ᵢ)</span>
<span id="cb1-954"><a href="#cb1-954" aria-hidden="true" tabindex="-1"></a>Expandable "Why maximize this?":</span>
<span id="cb1-955"><a href="#cb1-955" aria-hidden="true" tabindex="-1"></a>"This likelihood measures: how probable is our observed data y, given parameters β and α? Maximum likelihood estimation (MLE) finds the β that makes y most probable — the best explanation for what we observed."</span>
<span id="cb1-956"><a href="#cb1-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-957"><a href="#cb1-957" aria-hidden="true" tabindex="-1"></a>The Tuning Process</span>
<span id="cb1-958"><a href="#cb1-958" aria-hidden="true" tabindex="-1"></a>Manual tuning phase:</span>
<span id="cb1-959"><a href="#cb1-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-960"><a href="#cb1-960" aria-hidden="true" tabindex="-1"></a>User moves β sliders</span>
<span id="cb1-961"><a href="#cb1-961" aria-hidden="true" tabindex="-1"></a>All three panels update in real-time:</span>
<span id="cb1-962"><a href="#cb1-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-963"><a href="#cb1-963" aria-hidden="true" tabindex="-1"></a>η distribution shifts</span>
<span id="cb1-964"><a href="#cb1-964" aria-hidden="true" tabindex="-1"></a>Fitted μ values change, curve reshapes</span>
<span id="cb1-965"><a href="#cb1-965" aria-hidden="true" tabindex="-1"></a>Likelihood value changes</span>
<span id="cb1-966"><a href="#cb1-966" aria-hidden="true" tabindex="-1"></a>Position moves on contour plot</span>
<span id="cb1-967"><a href="#cb1-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-968"><a href="#cb1-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-969"><a href="#cb1-969" aria-hidden="true" tabindex="-1"></a>Gamification: "Try to maximize ℓ! Target: -189.23"</span>
<span id="cb1-970"><a href="#cb1-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-971"><a href="#cb1-971" aria-hidden="true" tabindex="-1"></a>Then: Algorithmic tuning</span>
<span id="cb1-972"><a href="#cb1-972" aria-hidden="true" tabindex="-1"></a>Buttons appear:</span>
<span id="cb1-973"><a href="#cb1-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-974"><a href="#cb1-974" aria-hidden="true" tabindex="-1"></a>"Optimize β with IRLS (standard)"</span>
<span id="cb1-975"><a href="#cb1-975" aria-hidden="true" tabindex="-1"></a>"Optimize β with gradient descent"</span>
<span id="cb1-976"><a href="#cb1-976" aria-hidden="true" tabindex="-1"></a>"Optimize (β, α) jointly" <span class="co">[</span><span class="ot">if α exists and isn't fixed</span><span class="co">]</span></span>
<span id="cb1-977"><a href="#cb1-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-978"><a href="#cb1-978" aria-hidden="true" tabindex="-1"></a>When clicked:</span>
<span id="cb1-979"><a href="#cb1-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-980"><a href="#cb1-980" aria-hidden="true" tabindex="-1"></a>Sliders animate to optimal values</span>
<span id="cb1-981"><a href="#cb1-981" aria-hidden="true" tabindex="-1"></a>Iteration counter shows progress</span>
<span id="cb1-982"><a href="#cb1-982" aria-hidden="true" tabindex="-1"></a>Path traced on contour plot</span>
<span id="cb1-983"><a href="#cb1-983" aria-hidden="true" tabindex="-1"></a>Convergence message</span>
<span id="cb1-984"><a href="#cb1-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-985"><a href="#cb1-985" aria-hidden="true" tabindex="-1"></a>Results panel:</span>
<span id="cb1-986"><a href="#cb1-986" aria-hidden="true" tabindex="-1"></a>Converged in 6 iterations!</span>
<span id="cb1-987"><a href="#cb1-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-988"><a href="#cb1-988" aria-hidden="true" tabindex="-1"></a>Optimal parameters:</span>
<span id="cb1-989"><a href="#cb1-989" aria-hidden="true" tabindex="-1"></a>  β̂₀ = -2.13  (SE: 0.31)</span>
<span id="cb1-990"><a href="#cb1-990" aria-hidden="true" tabindex="-1"></a>  β̂₁ =  0.67  (SE: 0.09)</span>
<span id="cb1-991"><a href="#cb1-991" aria-hidden="true" tabindex="-1"></a>  β̂₂ =  0.03  (SE: 0.01)</span>
<span id="cb1-992"><a href="#cb1-992" aria-hidden="true" tabindex="-1"></a>  β̂₃ =  0.45  (SE: 0.12)</span>
<span id="cb1-993"><a href="#cb1-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-994"><a href="#cb1-994" aria-hidden="true" tabindex="-1"></a>Maximum log-likelihood: -189.23</span>
<span id="cb1-995"><a href="#cb1-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-996"><a href="#cb1-996" aria-hidden="true" tabindex="-1"></a>Interpretation:</span>
<span id="cb1-997"><a href="#cb1-997" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Each additional day of log(stay) multiplies odds of </span>
<span id="cb1-998"><a href="#cb1-998" aria-hidden="true" tabindex="-1"></a>  readmission by exp(0.67) = 1.95</span>
<span id="cb1-999"><a href="#cb1-999" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Each additional year of age multiplies odds by </span>
<span id="cb1-1000"><a href="#cb1-1000" aria-hidden="true" tabindex="-1"></a>  exp(0.03) = 1.03</span>
<span id="cb1-1001"><a href="#cb1-1001" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Each prior admission multiplies odds by </span>
<span id="cb1-1002"><a href="#cb1-1002" aria-hidden="true" tabindex="-1"></a>  exp(0.45) = 1.57</span>
<span id="cb1-1003"><a href="#cb1-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1004"><a href="#cb1-1004" aria-hidden="true" tabindex="-1"></a>Special Attention: When α Exists</span>
<span id="cb1-1005"><a href="#cb1-1005" aria-hidden="true" tabindex="-1"></a>For models with dispersion parameters (Gaussian, Negative Binomial, Gamma), show:</span>
<span id="cb1-1006"><a href="#cb1-1006" aria-hidden="true" tabindex="-1"></a>Two-stage optimization:</span>
<span id="cb1-1007"><a href="#cb1-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1008"><a href="#cb1-1008" aria-hidden="true" tabindex="-1"></a>"Profile likelihood" approach:</span>
<span id="cb1-1009"><a href="#cb1-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1010"><a href="#cb1-1010" aria-hidden="true" tabindex="-1"></a>Fix α, optimize β</span>
<span id="cb1-1011"><a href="#cb1-1011" aria-hidden="true" tabindex="-1"></a>Then fix β, optimize α</span>
<span id="cb1-1012"><a href="#cb1-1012" aria-hidden="true" tabindex="-1"></a>Iterate until convergence</span>
<span id="cb1-1013"><a href="#cb1-1013" aria-hidden="true" tabindex="-1"></a>Show this as an animated cycle</span>
<span id="cb1-1014"><a href="#cb1-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1015"><a href="#cb1-1015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1016"><a href="#cb1-1016" aria-hidden="true" tabindex="-1"></a>Joint optimization:</span>
<span id="cb1-1017"><a href="#cb1-1017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1018"><a href="#cb1-1018" aria-hidden="true" tabindex="-1"></a>Optimize (β, α) simultaneously</span>
<span id="cb1-1019"><a href="#cb1-1019" aria-hidden="true" tabindex="-1"></a>Show 3D likelihood surface (if 1 β + α, i.e., 2D)</span>
<span id="cb1-1020"><a href="#cb1-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1021"><a href="#cb1-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1022"><a href="#cb1-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1023"><a href="#cb1-1023" aria-hidden="true" tabindex="-1"></a>Visual distinction:</span>
<span id="cb1-1024"><a href="#cb1-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1025"><a href="#cb1-1025" aria-hidden="true" tabindex="-1"></a>β sliders are blue (systematic)</span>
<span id="cb1-1026"><a href="#cb1-1026" aria-hidden="true" tabindex="-1"></a>α sliders are red (random/noise)</span>
<span id="cb1-1027"><a href="#cb1-1027" aria-hidden="true" tabindex="-1"></a>Likelihood depends on both: ℓ(β, α | y)</span>
<span id="cb1-1028"><a href="#cb1-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1029"><a href="#cb1-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1030"><a href="#cb1-1030" aria-hidden="true" tabindex="-1"></a>Page Flow Summary</span>
<span id="cb1-1031"><a href="#cb1-1031" aria-hidden="true" tabindex="-1"></a>User journey:</span>
<span id="cb1-1032"><a href="#cb1-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1033"><a href="#cb1-1033" aria-hidden="true" tabindex="-1"></a>Specify model structure (previous page): h(), g(), f()</span>
<span id="cb1-1034"><a href="#cb1-1034" aria-hidden="true" tabindex="-1"></a>Understand what needs tuning: β for systematic part, α for random part</span>
<span id="cb1-1035"><a href="#cb1-1035" aria-hidden="true" tabindex="-1"></a>Manually explore parameter space</span>
<span id="cb1-1036"><a href="#cb1-1036" aria-hidden="true" tabindex="-1"></a>Let algorithms find optimum</span>
<span id="cb1-1037"><a href="#cb1-1037" aria-hidden="true" tabindex="-1"></a>Interpret results</span>
<span id="cb1-1038"><a href="#cb1-1038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1039"><a href="#cb1-1039" aria-hidden="true" tabindex="-1"></a>Next page options:</span>
<span id="cb1-1040"><a href="#cb1-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1041"><a href="#cb1-1041" aria-hidden="true" tabindex="-1"></a>"Compare different loss functions →" (your Page 6 idea)</span>
<span id="cb1-1042"><a href="#cb1-1042" aria-hidden="true" tabindex="-1"></a>"Check model diagnostics →" (residuals, goodness-of-fit)</span>
<span id="cb1-1043"><a href="#cb1-1043" aria-hidden="true" tabindex="-1"></a>"Try a different model specification ←" (back to revise g() or f())</span>
<span id="cb1-1044"><a href="#cb1-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1045"><a href="#cb1-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1046"><a href="#cb1-1046" aria-hidden="true" tabindex="-1"></a>Does this properly distinguish y vs Y and set up the β vs α tuning distinction clearly? The visual flow from μ → Y → y is crucial for understanding where randomness enters the model.Yes. Please ensure y (observed response) and Y (modelled response) are distinguished. Y is where you placed it. y is a label on observed data which you correctly place below it.This will now help set up for the next page, where we show how the model has to be ‘tuned’, with g() tuned by Beta and f() tuned by alpha (which is sigma in most cases)19 NovPerfect! Let me make sure I have the notation crystal clear:</span>
<span id="cb1-1047"><a href="#cb1-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1048"><a href="#cb1-1048" aria-hidden="true" tabindex="-1"></a>Precise Notation Structure</span>
<span id="cb1-1049"><a href="#cb1-1049" aria-hidden="true" tabindex="-1"></a>The flow diagram shows:</span>
<span id="cb1-1050"><a href="#cb1-1050" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">X₁</span><span class="co">]</span> ─h₁()→ ┐</span>
<span id="cb1-1051"><a href="#cb1-1051" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">X₂</span><span class="co">]</span> ─h₂()→ ├─→ <span class="co">[</span><span class="ot">η = Xβ</span><span class="co">]</span> ─g⁻¹(·;β)→ <span class="co">[</span><span class="ot">μ</span><span class="co">]</span> ─f(·;μ,α)→ <span class="co">[</span><span class="ot">Y</span><span class="co">]</span></span>
<span id="cb1-1052"><a href="#cb1-1052" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">X₃</span><span class="co">]</span> ─h₃()→ ┘                                      ↓</span>
<span id="cb1-1053"><a href="#cb1-1053" aria-hidden="true" tabindex="-1"></a>                                              <span class="co">[</span><span class="ot">y</span><span class="co">]</span> (observed)</span>
<span id="cb1-1054"><a href="#cb1-1054" aria-hidden="true" tabindex="-1"></a>Key distinctions:</span>
<span id="cb1-1055"><a href="#cb1-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1056"><a href="#cb1-1056" aria-hidden="true" tabindex="-1"></a>g⁻¹(·; β): The inverse link function, parameterized by β</span>
<span id="cb1-1057"><a href="#cb1-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1058"><a href="#cb1-1058" aria-hidden="true" tabindex="-1"></a>Really it's g⁻¹(Xβ), so β "tunes" which values of μ we get</span>
<span id="cb1-1059"><a href="#cb1-1059" aria-hidden="true" tabindex="-1"></a>The link function itself isn't parameterized, but the linear predictor going into it is</span>
<span id="cb1-1060"><a href="#cb1-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1061"><a href="#cb1-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1062"><a href="#cb1-1062" aria-hidden="true" tabindex="-1"></a>f(·; μ, α): The probability distribution, parameterized by both μ and α</span>
<span id="cb1-1063"><a href="#cb1-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1064"><a href="#cb1-1064" aria-hidden="true" tabindex="-1"></a>μ comes from g⁻¹(Xβ) — so β indirectly tunes this</span>
<span id="cb1-1065"><a href="#cb1-1065" aria-hidden="true" tabindex="-1"></a>α is the dispersion/scale parameter (σ for Gaussian, θ for Negative Binomial, etc.)</span>
<span id="cb1-1066"><a href="#cb1-1066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1067"><a href="#cb1-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1068"><a href="#cb1-1068" aria-hidden="true" tabindex="-1"></a>Y: The random variable — what the model says could happen</span>
<span id="cb1-1069"><a href="#cb1-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1070"><a href="#cb1-1070" aria-hidden="true" tabindex="-1"></a>Y ~ f(μ, α)</span>
<span id="cb1-1071"><a href="#cb1-1071" aria-hidden="true" tabindex="-1"></a>Each observation Yᵢ ~ f(μᵢ, α)</span>
<span id="cb1-1072"><a href="#cb1-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1073"><a href="#cb1-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1074"><a href="#cb1-1074" aria-hidden="true" tabindex="-1"></a>y: The actual observed data — what did happen</span>
<span id="cb1-1075"><a href="#cb1-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1076"><a href="#cb1-1076" aria-hidden="true" tabindex="-1"></a>Specific realization: y = (y₁, y₂, ..., yₙ)</span>
<span id="cb1-1077"><a href="#cb1-1077" aria-hidden="true" tabindex="-1"></a>Shown below Y with arrow indicating "one realization"</span>
<span id="cb1-1078"><a href="#cb1-1078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1079"><a href="#cb1-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1080"><a href="#cb1-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1081"><a href="#cb1-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1082"><a href="#cb1-1082" aria-hidden="true" tabindex="-1"></a>Transition Text to Tuning Page</span>
<span id="cb1-1083"><a href="#cb1-1083" aria-hidden="true" tabindex="-1"></a>At end of model specification:</span>
<span id="cb1-1084"><a href="#cb1-1084" aria-hidden="true" tabindex="-1"></a>"Your model is now fully specified:</span>
<span id="cb1-1085"><a href="#cb1-1085" aria-hidden="true" tabindex="-1"></a>Structure defined:</span>
<span id="cb1-1086"><a href="#cb1-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1087"><a href="#cb1-1087" aria-hidden="true" tabindex="-1"></a>Predictor transformations h(X)</span>
<span id="cb1-1088"><a href="#cb1-1088" aria-hidden="true" tabindex="-1"></a>Link function g⁻¹(·)</span>
<span id="cb1-1089"><a href="#cb1-1089" aria-hidden="true" tabindex="-1"></a>Distribution family f(·)</span>
<span id="cb1-1090"><a href="#cb1-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1091"><a href="#cb1-1091" aria-hidden="true" tabindex="-1"></a>Parameters to tune:</span>
<span id="cb1-1092"><a href="#cb1-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1093"><a href="#cb1-1093" aria-hidden="true" tabindex="-1"></a>β: tunes g⁻¹(·) — determines where μ lands based on X</span>
<span id="cb1-1094"><a href="#cb1-1094" aria-hidden="true" tabindex="-1"></a>α: tunes f(·) — determines how spread out Y is around μ</span>
<span id="cb1-1095"><a href="#cb1-1095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1096"><a href="#cb1-1096" aria-hidden="true" tabindex="-1"></a>We need to find the β and α values that best explain our observed data y."</span>
<span id="cb1-1097"><a href="#cb1-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1098"><a href="#cb1-1098" aria-hidden="true" tabindex="-1"></a>Next Page: "Tuning β and α"</span>
<span id="cb1-1099"><a href="#cb1-1099" aria-hidden="true" tabindex="-1"></a>Title: "Finding the parameters that fit your data"</span>
<span id="cb1-1100"><a href="#cb1-1100" aria-hidden="true" tabindex="-1"></a>Opening explanation panel:</span>
<span id="cb1-1101"><a href="#cb1-1101" aria-hidden="true" tabindex="-1"></a>Your model has two types of parameters:</span>
<span id="cb1-1102"><a href="#cb1-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1103"><a href="#cb1-1103" aria-hidden="true" tabindex="-1"></a>┌─ β (systematic parameters) ──────────────┐</span>
<span id="cb1-1104"><a href="#cb1-1104" aria-hidden="true" tabindex="-1"></a>│ Controls: WHERE the expected values are  │</span>
<span id="cb1-1105"><a href="#cb1-1105" aria-hidden="true" tabindex="-1"></a>│ Via: μ = g⁻¹(Xβ)                         │</span>
<span id="cb1-1106"><a href="#cb1-1106" aria-hidden="true" tabindex="-1"></a>│ In your model: β = (β₀, β₁, β₂, ...)    │</span>
<span id="cb1-1107"><a href="#cb1-1107" aria-hidden="true" tabindex="-1"></a>└──────────────────────────────────────────┘</span>
<span id="cb1-1108"><a href="#cb1-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1109"><a href="#cb1-1109" aria-hidden="true" tabindex="-1"></a>┌─ α (dispersion parameter) ───────────────┐</span>
<span id="cb1-1110"><a href="#cb1-1110" aria-hidden="true" tabindex="-1"></a>│ Controls: HOW SPREAD OUT observations    │</span>
<span id="cb1-1111"><a href="#cb1-1111" aria-hidden="true" tabindex="-1"></a>│           are around their expected values│</span>
<span id="cb1-1112"><a href="#cb1-1112" aria-hidden="true" tabindex="-1"></a>│ Via: Var(Y) = V(μ) × α                   │</span>
<span id="cb1-1113"><a href="#cb1-1113" aria-hidden="true" tabindex="-1"></a>│ In your model: α = σ² <span class="co">[</span><span class="ot">for Gaussian</span><span class="co">]</span>     │</span>
<span id="cb1-1114"><a href="#cb1-1114" aria-hidden="true" tabindex="-1"></a>│                α = θ  <span class="co">[</span><span class="ot">for Neg. Binomial</span><span class="co">]</span> │</span>
<span id="cb1-1115"><a href="#cb1-1115" aria-hidden="true" tabindex="-1"></a>└──────────────────────────────────────────┘</span>
<span id="cb1-1116"><a href="#cb1-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1117"><a href="#cb1-1117" aria-hidden="true" tabindex="-1"></a>Goal: Find (β̂, α̂) that maximize:</span>
<span id="cb1-1118"><a href="#cb1-1118" aria-hidden="true" tabindex="-1"></a>  ℓ(β, α) = Σᵢ log f(yᵢ; μᵢ(β), α)</span>
<span id="cb1-1119"><a href="#cb1-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1120"><a href="#cb1-1120" aria-hidden="true" tabindex="-1"></a>Interactive Parameter Controls</span>
<span id="cb1-1121"><a href="#cb1-1121" aria-hidden="true" tabindex="-1"></a>Split layout:</span>
<span id="cb1-1122"><a href="#cb1-1122" aria-hidden="true" tabindex="-1"></a>Left Panel: β Parameters (Systematic)</span>
<span id="cb1-1123"><a href="#cb1-1123" aria-hidden="true" tabindex="-1"></a>Linear predictor: η = Xβ</span>
<span id="cb1-1124"><a href="#cb1-1124" aria-hidden="true" tabindex="-1"></a>Controls the expected values μ = g⁻¹(η)</span>
<span id="cb1-1125"><a href="#cb1-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1126"><a href="#cb1-1126" aria-hidden="true" tabindex="-1"></a>β₀ (Intercept):        <span class="co">[</span><span class="ot">━━━●━━━━━━</span><span class="co">]</span> 0.00</span>
<span id="cb1-1127"><a href="#cb1-1127" aria-hidden="true" tabindex="-1"></a>                       <span class="co">[</span><span class="ot">-5 ←→ 5</span><span class="co">]</span></span>
<span id="cb1-1128"><a href="#cb1-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1129"><a href="#cb1-1129" aria-hidden="true" tabindex="-1"></a>β₁ (log_stay):         <span class="co">[</span><span class="ot">━━━●━━━━━━</span><span class="co">]</span> 0.00  </span>
<span id="cb1-1130"><a href="#cb1-1130" aria-hidden="true" tabindex="-1"></a>                       <span class="co">[</span><span class="ot">-3 ←→ 3</span><span class="co">]</span></span>
<span id="cb1-1131"><a href="#cb1-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1132"><a href="#cb1-1132" aria-hidden="true" tabindex="-1"></a>β₂ (age):              <span class="co">[</span><span class="ot">━━━●━━━━━━</span><span class="co">]</span> 0.00</span>
<span id="cb1-1133"><a href="#cb1-1133" aria-hidden="true" tabindex="-1"></a>                       <span class="co">[</span><span class="ot">-0.5 ←→ 0.5</span><span class="co">]</span></span>
<span id="cb1-1134"><a href="#cb1-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1135"><a href="#cb1-1135" aria-hidden="true" tabindex="-1"></a>Currently: μ̄ = 0.47 (mean fitted probability)</span>
<span id="cb1-1136"><a href="#cb1-1136" aria-hidden="true" tabindex="-1"></a>Right Panel: α Parameter (Random)</span>
<span id="cb1-1137"><a href="#cb1-1137" aria-hidden="true" tabindex="-1"></a>For Gaussian:</span>
<span id="cb1-1138"><a href="#cb1-1138" aria-hidden="true" tabindex="-1"></a>Noise level: Var(Y|μ) = σ²</span>
<span id="cb1-1139"><a href="#cb1-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1140"><a href="#cb1-1140" aria-hidden="true" tabindex="-1"></a>σ² (variance):         <span class="co">[</span><span class="ot">━━━●━━━━━━</span><span class="co">]</span> 1.00</span>
<span id="cb1-1141"><a href="#cb1-1141" aria-hidden="true" tabindex="-1"></a>                       <span class="co">[</span><span class="ot">0.1 ←→ 10</span><span class="co">]</span></span>
<span id="cb1-1142"><a href="#cb1-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1143"><a href="#cb1-1143" aria-hidden="true" tabindex="-1"></a>Currently: typical deviation = ±1.0</span>
<span id="cb1-1144"><a href="#cb1-1144" aria-hidden="true" tabindex="-1"></a>For Negative Binomial:</span>
<span id="cb1-1145"><a href="#cb1-1145" aria-hidden="true" tabindex="-1"></a>Overdispersion: Var(Y|μ) = μ + μ²/θ</span>
<span id="cb1-1146"><a href="#cb1-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1147"><a href="#cb1-1147" aria-hidden="true" tabindex="-1"></a>θ (dispersion):        <span class="co">[</span><span class="ot">━━━●━━━━━━</span><span class="co">]</span> 1.00</span>
<span id="cb1-1148"><a href="#cb1-1148" aria-hidden="true" tabindex="-1"></a>                       <span class="co">[</span><span class="ot">0.1 ←→ 20</span><span class="co">]</span></span>
<span id="cb1-1149"><a href="#cb1-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1150"><a href="#cb1-1150" aria-hidden="true" tabindex="-1"></a>Currently: variance is 2× mean (θ=1 → moderate overdispersion)</span>
<span id="cb1-1151"><a href="#cb1-1151" aria-hidden="true" tabindex="-1"></a>Lower θ → more overdispersion</span>
<span id="cb1-1152"><a href="#cb1-1152" aria-hidden="true" tabindex="-1"></a>For Binomial (Bernoulli):</span>
<span id="cb1-1153"><a href="#cb1-1153" aria-hidden="true" tabindex="-1"></a>No extra parameter needed!</span>
<span id="cb1-1154"><a href="#cb1-1154" aria-hidden="true" tabindex="-1"></a>Var(Y|μ) = μ(1-μ) <span class="co">[</span><span class="ot">variance determined by mean</span><span class="co">]</span></span>
<span id="cb1-1155"><a href="#cb1-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1156"><a href="#cb1-1156" aria-hidden="true" tabindex="-1"></a>α is fixed by the distribution</span>
<span id="cb1-1157"><a href="#cb1-1157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1158"><a href="#cb1-1158" aria-hidden="true" tabindex="-1"></a>Visualization Panels (updating in real-time)</span>
<span id="cb1-1159"><a href="#cb1-1159" aria-hidden="true" tabindex="-1"></a>Panel 1: How β affects μ</span>
<span id="cb1-1160"><a href="#cb1-1160" aria-hidden="true" tabindex="-1"></a>Left plot: Linear predictor η = Xβ</span>
<span id="cb1-1161"><a href="#cb1-1161" aria-hidden="true" tabindex="-1"></a>  • Histogram of ηᵢ for all observations</span>
<span id="cb1-1162"><a href="#cb1-1162" aria-hidden="true" tabindex="-1"></a>  • As β changes, this distribution shifts/spreads</span>
<span id="cb1-1163"><a href="#cb1-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1164"><a href="#cb1-1164" aria-hidden="true" tabindex="-1"></a>Right plot: Expected values μ = g⁻¹(η)  </span>
<span id="cb1-1165"><a href="#cb1-1165" aria-hidden="true" tabindex="-1"></a>  • Histogram of μᵢ for all observations</span>
<span id="cb1-1166"><a href="#cb1-1166" aria-hidden="true" tabindex="-1"></a>  • Shows: β controls where μ values concentrate</span>
<span id="cb1-1167"><a href="#cb1-1167" aria-hidden="true" tabindex="-1"></a>Panel 2: How α affects the spread of Y around μ</span>
<span id="cb1-1168"><a href="#cb1-1168" aria-hidden="true" tabindex="-1"></a>For a few example observations, show:</span>
<span id="cb1-1169"><a href="#cb1-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1170"><a href="#cb1-1170" aria-hidden="true" tabindex="-1"></a>μ₁ = 0.3  →  Y₁ ~ f(0.3, α)  <span class="co">[</span><span class="ot">probability distribution shown</span><span class="co">]</span></span>
<span id="cb1-1171"><a href="#cb1-1171" aria-hidden="true" tabindex="-1"></a>μ₂ = 0.7  →  Y₂ ~ f(0.7, α)  <span class="co">[</span><span class="ot">probability distribution shown</span><span class="co">]</span></span>
<span id="cb1-1172"><a href="#cb1-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1173"><a href="#cb1-1173" aria-hidden="true" tabindex="-1"></a>As α changes:</span>
<span id="cb1-1174"><a href="#cb1-1174" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gaussian: curves widen/narrow (σ changes)</span>
<span id="cb1-1175"><a href="#cb1-1175" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Neg. Binomial: variance increases/decreases relative to mean</span>
<span id="cb1-1176"><a href="#cb1-1176" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gamma: shape of distribution changes</span>
<span id="cb1-1177"><a href="#cb1-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1178"><a href="#cb1-1178" aria-hidden="true" tabindex="-1"></a>Overlay observed y values to show fit</span>
<span id="cb1-1179"><a href="#cb1-1179" aria-hidden="true" tabindex="-1"></a>Panel 3: Data vs. Model</span>
<span id="cb1-1180"><a href="#cb1-1180" aria-hidden="true" tabindex="-1"></a>Scatter plot: observed y vs. fitted μ</span>
<span id="cb1-1181"><a href="#cb1-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1182"><a href="#cb1-1182" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Perfect fit would have all points on y = μ line</span>
<span id="cb1-1183"><a href="#cb1-1183" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>β determines where the fitted values fall</span>
<span id="cb1-1184"><a href="#cb1-1184" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>α determines how much scatter around the line we expect</span>
<span id="cb1-1185"><a href="#cb1-1185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1186"><a href="#cb1-1186" aria-hidden="true" tabindex="-1"></a>Visual: </span>
<span id="cb1-1187"><a href="#cb1-1187" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Points are observed (yᵢ, μᵢ) pairs</span>
<span id="cb1-1188"><a href="#cb1-1188" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Shaded envelope shows ±1 SD based on α</span>
<span id="cb1-1189"><a href="#cb1-1189" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>As α increases, envelope widens</span>
<span id="cb1-1190"><a href="#cb1-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1191"><a href="#cb1-1191" aria-hidden="true" tabindex="-1"></a>Likelihood Display</span>
<span id="cb1-1192"><a href="#cb1-1192" aria-hidden="true" tabindex="-1"></a>Real-time updating:</span>
<span id="cb1-1193"><a href="#cb1-1193" aria-hidden="true" tabindex="-1"></a>Log-likelihood: ℓ(β, α | y) = Σᵢ log f(yᵢ; μᵢ(β), α)</span>
<span id="cb1-1194"><a href="#cb1-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1195"><a href="#cb1-1195" aria-hidden="true" tabindex="-1"></a>Current value: -234.56</span>
<span id="cb1-1196"><a href="#cb1-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1197"><a href="#cb1-1197" aria-hidden="true" tabindex="-1"></a>This measures: How probable is our observed data y,</span>
<span id="cb1-1198"><a href="#cb1-1198" aria-hidden="true" tabindex="-1"></a>               given parameters β and α?</span>
<span id="cb1-1199"><a href="#cb1-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1200"><a href="#cb1-1200" aria-hidden="true" tabindex="-1"></a>Goal: Maximize this! (find the β and α that make y most likely)</span>
<span id="cb1-1201"><a href="#cb1-1201" aria-hidden="true" tabindex="-1"></a>For models with α:</span>
<span id="cb1-1202"><a href="#cb1-1202" aria-hidden="true" tabindex="-1"></a>Note: Some algorithms fix α first, optimize β, </span>
<span id="cb1-1203"><a href="#cb1-1203" aria-hidden="true" tabindex="-1"></a>      then update α. This is called "REML" or </span>
<span id="cb1-1204"><a href="#cb1-1204" aria-hidden="true" tabindex="-1"></a>      "profile likelihood" when appropriate.</span>
<span id="cb1-1205"><a href="#cb1-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1206"><a href="#cb1-1206" aria-hidden="true" tabindex="-1"></a>Optimization Controls</span>
<span id="cb1-1207"><a href="#cb1-1207" aria-hidden="true" tabindex="-1"></a>Manual exploration first:</span>
<span id="cb1-1208"><a href="#cb1-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1209"><a href="#cb1-1209" aria-hidden="true" tabindex="-1"></a>User adjusts sliders</span>
<span id="cb1-1210"><a href="#cb1-1210" aria-hidden="true" tabindex="-1"></a>All visualizations update</span>
<span id="cb1-1211"><a href="#cb1-1211" aria-hidden="true" tabindex="-1"></a>Likelihood value changes</span>
<span id="cb1-1212"><a href="#cb1-1212" aria-hidden="true" tabindex="-1"></a>"Try to maximize ℓ!"</span>
<span id="cb1-1213"><a href="#cb1-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1214"><a href="#cb1-1214" aria-hidden="true" tabindex="-1"></a>Then algorithmic:</span>
<span id="cb1-1215"><a href="#cb1-1215" aria-hidden="true" tabindex="-1"></a>Optimize β (with α fixed):</span>
<span id="cb1-1216"><a href="#cb1-1216" aria-hidden="true" tabindex="-1"></a>  <span class="co">[</span><span class="ot">Button: IRLS</span><span class="co">] [Button: Newton-Raphson]</span> <span class="co">[</span><span class="ot">Button: Gradient Descent</span><span class="co">]</span></span>
<span id="cb1-1217"><a href="#cb1-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1218"><a href="#cb1-1218" aria-hidden="true" tabindex="-1"></a>Optimize α (with β fixed):  </span>
<span id="cb1-1219"><a href="#cb1-1219" aria-hidden="true" tabindex="-1"></a>  <span class="co">[</span><span class="ot">Button: Profile Likelihood</span><span class="co">] [Button: REML]</span></span>
<span id="cb1-1220"><a href="#cb1-1220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1221"><a href="#cb1-1221" aria-hidden="true" tabindex="-1"></a>Optimize (β, α) jointly:</span>
<span id="cb1-1222"><a href="#cb1-1222" aria-hidden="true" tabindex="-1"></a>  <span class="co">[</span><span class="ot">Button: Joint Optimization</span><span class="co">]</span></span>
<span id="cb1-1223"><a href="#cb1-1223" aria-hidden="true" tabindex="-1"></a>Animation shows:</span>
<span id="cb1-1224"><a href="#cb1-1224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1225"><a href="#cb1-1225" aria-hidden="true" tabindex="-1"></a>Parameters converging</span>
<span id="cb1-1226"><a href="#cb1-1226" aria-hidden="true" tabindex="-1"></a>Likelihood increasing</span>
<span id="cb1-1227"><a href="#cb1-1227" aria-hidden="true" tabindex="-1"></a>Iteration count</span>
<span id="cb1-1228"><a href="#cb1-1228" aria-hidden="true" tabindex="-1"></a>Convergence diagnostics</span>
<span id="cb1-1229"><a href="#cb1-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1230"><a href="#cb1-1230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1231"><a href="#cb1-1231" aria-hidden="true" tabindex="-1"></a>Results Display</span>
<span id="cb1-1232"><a href="#cb1-1232" aria-hidden="true" tabindex="-1"></a>Optimization complete!</span>
<span id="cb1-1233"><a href="#cb1-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1234"><a href="#cb1-1234" aria-hidden="true" tabindex="-1"></a>Systematic parameters (β):</span>
<span id="cb1-1235"><a href="#cb1-1235" aria-hidden="true" tabindex="-1"></a>  β̂₀ = -2.13  (SE: 0.31)</span>
<span id="cb1-1236"><a href="#cb1-1236" aria-hidden="true" tabindex="-1"></a>  β̂₁ =  0.67  (SE: 0.09)  </span>
<span id="cb1-1237"><a href="#cb1-1237" aria-hidden="true" tabindex="-1"></a>  β̂₂ =  0.03  (SE: 0.01)</span>
<span id="cb1-1238"><a href="#cb1-1238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1239"><a href="#cb1-1239" aria-hidden="true" tabindex="-1"></a>Dispersion parameter (α):</span>
<span id="cb1-1240"><a href="#cb1-1240" aria-hidden="true" tabindex="-1"></a>  σ̂² = 1.45  (SE: 0.08)  <span class="co">[</span><span class="ot">for Gaussian</span><span class="co">]</span></span>
<span id="cb1-1241"><a href="#cb1-1241" aria-hidden="true" tabindex="-1"></a>  or</span>
<span id="cb1-1242"><a href="#cb1-1242" aria-hidden="true" tabindex="-1"></a>  θ̂ = 2.34  (SE: 0.42)   <span class="co">[</span><span class="ot">for Negative Binomial</span><span class="co">]</span></span>
<span id="cb1-1243"><a href="#cb1-1243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1244"><a href="#cb1-1244" aria-hidden="true" tabindex="-1"></a>Maximum log-likelihood: -189.23</span>
<span id="cb1-1245"><a href="#cb1-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1246"><a href="#cb1-1246" aria-hidden="true" tabindex="-1"></a>AIC: 386.46  (penalizes model complexity)</span>
<span id="cb1-1247"><a href="#cb1-1247" aria-hidden="true" tabindex="-1"></a>BIC: 398.21  (penalizes complexity more heavily)</span>
<span id="cb1-1248"><a href="#cb1-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1249"><a href="#cb1-1249" aria-hidden="true" tabindex="-1"></a>Does this correctly distinguish:</span>
<span id="cb1-1250"><a href="#cb1-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1251"><a href="#cb1-1251" aria-hidden="true" tabindex="-1"></a>β tunes g() via the linear predictor Xβ that feeds into g⁻¹</span>
<span id="cb1-1252"><a href="#cb1-1252" aria-hidden="true" tabindex="-1"></a>α tunes f() as the dispersion/scale parameter</span>
<span id="cb1-1253"><a href="#cb1-1253" aria-hidden="true" tabindex="-1"></a>Y is the random variable (model)</span>
<span id="cb1-1254"><a href="#cb1-1254" aria-hidden="true" tabindex="-1"></a>y is the observed data (reality)</span>
<span id="cb1-1255"><a href="#cb1-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1256"><a href="#cb1-1256" aria-hidden="true" tabindex="-1"></a>And sets up clearly that we need to find optimal (β̂, α̂) to fit the model to data?</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Built with <a href="https://quarto.org">Quarto</a></div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">Part of <a href="https://jonminton.github.io/JonStats/">JonStats</a></div>
  </div>
</footer>



</body></html>